<!doctype html><html lang="en"><head><title data-rh="true">Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2021-09-13T07:52:05.992Z"/><meta data-rh="true" name="title" content="Neural Network Pruning 101. All you need to know not to get lost | by Hugo Tessier | Towards Data Science"/><meta data-rh="true" property="og:title" content="Neural Network Pruning 101"/><meta data-rh="true" property="al:android:url" content="medium://p/af816aaea61"/><meta data-rh="true" property="al:ios:url" content="medium://p/af816aaea61"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…"/><meta data-rh="true" property="og:description" content="All you need to know not to get lost"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" property="article:author" content="https://medium.com/@hugo.tessier"/><meta data-rh="true" name="author" content="Hugo Tessier"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Neural Network Pruning 101"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/af816aaea61"/><meta data-rh="true" property="twitter:description" content="All you need to know not to get lost"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="22 min read"/><meta data-rh="true" name="twitter:tile:template:testing" content="2"/><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/resize:fit:1200/1*7qwYH1r-h6VOGiE6C2tpGg.png"/><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"/><meta data-rh="true" name="twitter:tile:info1:text" content="Hugo Tessier"/><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"/><meta data-rh="true" name="twitter:tile:info2:text" content="Sep 13, 2021"/><meta data-rh="true" name="twitter:cta" content="Read on Medium"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@hugo.tessier"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/neural-network-pruning-101-af816aaea61"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/af816aaea61"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*7qwYH1r-h6VOGiE6C2tpGg.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","dateCreated":"2021-09-09T06:36:56.338Z","datePublished":"2021-09-09T06:36:56.338Z","dateModified":"2022-07-29T12:31:29.365Z","headline":"Neural Network Pruning 101 - Towards Data Science","name":"Neural Network Pruning 101 - Towards Data Science","description":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or…","identifier":"af816aaea61","author":{"@type":"Person","name":"Hugo Tessier","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@hugo.tessier"},"creator":["Hugo Tessier"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61"}</script><style type="text/css" data-fela-rehydration="489" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px rgba(242, 242, 242, 1)}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ad{flex:1 0 auto}.ae{color:inherit}.af{fill:inherit}.ag{font-size:inherit}.ah{border:inherit}.ai{font-family:inherit}.aj{letter-spacing:inherit}.ak{font-weight:inherit}.al{padding:0}.am{margin:0}.an{cursor:pointer}.ao:disabled{cursor:not-allowed}.ap:disabled{color:rgba(117, 117, 117, 1)}.aq:disabled{fill:rgba(117, 117, 117, 1)}.at{height:25px}.au{fill:rgba(41, 41, 41, 1)}.av{margin-left:16px}.aw{border:none}.ax{border-radius:20px}.ay{width:240px}.az{background:rgba(250, 250, 250, 1)}.ba path{fill:rgba(117, 117, 117, 1)}.bc{outline:none}.bd{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.be{font-size:14px}.bf{width:100%}.bg{padding:10px 20px 10px 0}.bh{background-color:transparent}.bi{color:rgba(41, 41, 41, 1)}.bj::placeholder{color:rgba(117, 117, 117, 1)}.bk{display:inline-block}.bl{margin-left:12px}.bm{margin-right:12px}.bn{border-radius:4px}.bo{margin-left:24px}.bp{height:24px}.bv{background-color:rgba(250, 250, 250, 1)}.bw{border-radius:50%}.bx{height:32px}.by{width:32px}.bz{margin:auto}.ca{max-width:1336px}.cb{flex-direction:row}.cc{justify-content:space-evenly}.cj{flex:1 1 auto}.ck{height:100vh}.cl{justify-content:center}.cm{padding-right:24px}.de{box-sizing:border-box}.df{border-left:1px solid rgba(242, 242, 242, 1)}.dg{min-height:100vh}.dh{height:100%}.di{position:relative}.dj{margin-left:8px}.dk{color:rgba(117, 117, 117, 1)}.dl{font-size:13px}.eb{color:rgba(255, 255, 255, 1)}.ec{fill:rgba(255, 255, 255, 1)}.ed{background:rgba(102, 138, 170, 1)}.ee{border-color:rgba(102, 138, 170, 1)}.ei:disabled{cursor:inherit !important}.ej:disabled{opacity:0.3}.ek:disabled:hover{background:rgba(102, 138, 170, 1)}.el:disabled:hover{border-color:rgba(102, 138, 170, 1)}.em{border-radius:99em}.eo{border-width:1px}.ep{border-style:solid}.eq{text-decoration:none}.et{margin-right:32px}.eu{fill:rgba(117, 117, 117, 1)}.ex{background:transparent}.ey svg{margin-left:4px}.ez svg{fill:rgba(117, 117, 117, 1)}.fb{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fc{position:absolute}.fe{background-color:rgba(242, 242, 242, 1)}.ff{border-bottom:1px solid rgba(230, 230, 230, 1)}.fg{min-width:0}.fh{margin:0 24px}.fl{height:56px}.fm{margin-right:16px}.fn{margin-right:3px}.fo{flex:0 0 auto}.fp{overflow:hidden}.fq{max-height:20px}.fr{text-overflow:ellipsis}.fs{display:-webkit-box}.ft{-webkit-line-clamp:1}.fu{-webkit-box-orient:vertical}.fv{word-break:break-all}.gh{margin-left:auto}.gi{margin-right:auto}.gj{max-width:728px}.gu{align-items:flex-start}.gv{justify-content:space-between}.gw{height:48px}.gx{width:48px}.gy{font-size:16px}.gz{line-height:24px}.ha{margin-bottom:4px}.hb{padding-left:12px}.hf{padding:0px 8px 1px}.hg{flex-wrap:wrap}.hh{padding:0 8px}.hi{padding-right:4px}.hj{padding:8px 2px}.hk path{fill:rgba(168, 168, 168, 1)}.hm{margin:0 16px 0 28px}.hn path{fill:rgba(41, 41, 41, 1)}.hq svg path{fill:rgba(117, 117, 117, 1)}.hr{padding-top:24px}.hs{border:1px solid rgba(230, 230, 230, 1)}.ht{padding:6px 15px 6px 10px}.hv svg{margin-right:8px}.hw{padding-right:12px}.hx{background:rgba(255, 255, 255, 1)}.hy{box-shadow:0 1px 4px rgba(230, 230, 230, 1)}.hz{max-height:100vh}.ia{overflow-y:auto}.ib{left:0}.ic{top:calc(100vh + 100px)}.id{bottom:calc(100vh + 100px)}.ie{width:10px}.if{pointer-events:none}.ig{word-break:break-word}.ih{word-wrap:break-word}.ii:after{display:block}.ij:after{content:""}.ik:after{clear:both}.il{line-height:1.23}.im{letter-spacing:0}.in{font-style:normal}.io{font-weight:700}.jj{margin-bottom:-0.27em}.jk{line-height:1.394}.jl{font-size:24px}.kb{margin-bottom:-0.42em}.kc{line-height:1.58}.kd{letter-spacing:-0.004em}.ke{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.kx{margin-bottom:-0.46em}.ky{line-height:1.31}.kz{letter-spacing:-0.022em}.la{font-weight:600}.lp{margin-bottom:-0.37em}.lv{max-width:2430px}.ma{clear:both}.mc{cursor:zoom-in}.md{z-index:auto}.mf{max-width:100%}.mg{height:auto}.mh{margin-top:10px}.mi{text-align:center}.ml{line-height:1.18}.mw{margin-bottom:-0.31em}.mx{font-style:italic}.my{text-decoration:underline}.mz{max-width:2268px}.na{max-width:2048px}.nb{max-width:2058px}.nc{padding-bottom:100%}.nd{height:0}.ne{margin-bottom:26px}.nf{margin-top:6px}.ng{margin-top:8px}.nh{margin-right:8px}.ni{padding:8px 16px}.nj{border-radius:100px}.nk{transition:background 300ms ease}.nm{white-space:nowrap}.nn{border-top:none}.nt{height:52px}.nu{max-height:52px}.nv{box-sizing:content-box}.nw{position:static}.nx{z-index:1}.nz{max-width:155px}.oc{margin-right:4px}.of{-webkit-user-select:none}.og{border:0}.oj{outline:0}.ok{user-select:none}.ol> svg{pointer-events:none}.ou{cursor:progress}.ox{margin-top:0px}.oy{opacity:1}.oz{padding:4px 0}.pb{margin-left:4px}.pc svg{color:rgba(117, 117, 117, 1)}.pf{margin-left:20px}.pg{margin-right:20px}.ph{padding-bottom:4px}.pi{padding-top:32px}.pj{font-weight:500}.pp{padding:7px 16px 9px}.pq{padding-top:5px}.pr{padding-top:25px}.ps{padding-bottom:96px}.pt{padding-top:40px}.pu{padding:30px 0}.pv{margin-bottom:0}.pw{min-width:100vw}.px{right:0}.py{bottom:0}.pz{background-color:rgba(0, 0, 0, 1)}.qg{max-width:1192px}.qh:disabled{color:rgba(255, 255, 255, 0.6)}.qi:disabled{fill:rgba(255, 255, 255, 0.45)}.ql{height:22px}.qm{margin-top:20px}.qn{color:rgba(255, 255, 255, 0.95)}.qp{height:1px}.qq{background-color:rgba(255, 255, 255, 0.4)}.qr{margin:28px 0 20px}.qs{top:57px}.qt{min-height:calc(100vh - 57px)}.qu{flex-direction:column}.qv{padding-bottom:0px}.qw{border-bottom:none}.qx{margin-top:40px}.qy{height:88px}.qz{width:88px}.ra{margin-top:16px}.rb{margin-top:4px}.rc{margin-top:12px}.rd{margin-bottom:40px}.re{margin-top:24px}.rf{width:auto}.rg{stroke:rgba(242, 242, 242, 1)}.rh{height:36px}.ri{width:36px}.rj{color:rgba(242, 242, 242, 1)}.rk{fill:rgba(242, 242, 242, 1)}.rl{background:rgba(242, 242, 242, 1)}.rm{border-color:rgba(242, 242, 242, 1)}.rs{padding:24px 0}.rt{margin-right:6px}.ru{font-size:11px}.rv{line-height:16px}.ar:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.as:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.ef:hover{background:rgba(90, 118, 144, 1)}.eg:hover{border-color:rgba(90, 118, 144, 1)}.eh:hover{cursor:pointer}.ev:hover{color:rgba(41, 41, 41, 1)}.ew:hover{fill:rgba(41, 41, 41, 1)}.fa:hover svg{fill:rgba(41, 41, 41, 1)}.fd:hover{background-color:none}.hl:hover path{fill:rgba(8, 8, 8, 1)}.ho:hover:not(:disabled) svg path{fill:rgba(8, 8, 8, 1)}.hu:hover{border-color:rgba(204, 204, 204, 1)}.nl:hover{background-color:rgba(230, 230, 230, 1)}.oi:hover{fill:rgba(8, 8, 8, 1)}.pa:hover p{color:rgba(8, 8, 8, 1)}.pd:hover svg{color:rgba(8, 8, 8, 1)}.qj:hover:not(:disabled){color:rgba(255, 255, 255, 1)}.qk:hover:not(:disabled){fill:rgba(255, 255, 255, 0.9)}.qo:hover{text-decoration:underline}.rn:hover{background:rgba(242, 242, 242, 1)}.ro:hover{border-color:rgba(242, 242, 242, 1)}.rp:hover{cursor:wait}.rq:hover{color:rgba(242, 242, 242, 1)}.rr:hover{fill:rgba(242, 242, 242, 1)}.bb:focus-within path{fill:rgba(41, 41, 41, 1)}.hp:focus svg path{fill:rgba(8, 8, 8, 1)}.me:focus{transform:scale(1.01)}.oh:focus{fill:rgba(8, 8, 8, 1)}.pe:focus svg{color:rgba(8, 8, 8, 1)}.om:active{border-style:none}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bu{width:64px}.cd{max-width:728px}.ce{min-width:728px}.da{padding-left:clamp(24px, 24px + 100vw - 1080px, 40px)}.db{display:block}.dc{min-width:368px}.dd{max-width:368px}.du{font-size:14px}.dv{line-height:20px}.ea{padding:4px 12px 6px}.es{display:flex}.fk{max-width:680px}.gb{margin-bottom:68px}.gg{padding:0 16px}.gs{margin-bottom:32px}.gt{margin-top:56px}.jf{font-size:32px}.jg{margin-top:0.6em}.jh{line-height:40px}.ji{letter-spacing:-0.016em}.jy{margin-top:0.79em}.jz{font-size:22px}.ka{line-height:28px}.kt{font-size:20px}.ku{margin-top:2em}.kv{line-height:32px}.kw{letter-spacing:-0.003em}.ln{margin-top:3.14em}.lo{letter-spacing:0}.lu{margin-top:0.86em}.mu{margin-top:2.37em}.mv{line-height:24px}.ns{margin-bottom:26px}.ot{margin-top:0px}.ow{display:inline-block}.po{max-height:24px}.qf{margin:0 64px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.mj{margin-left:auto}.mk{text-align:center}.os{margin-top:0px}.ov{display:inline-block}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.ob{display:inline-block}.or{margin-top:0px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.oa{display:inline-block}.op{margin-top:0px}.oq{margin-right:0px}.qa{padding:24px 0}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.bq{width:24px}.ci{min-width:0}.cn{padding-left:24px}.co{min-width:352px}.cp{max-width:352px}.dm{font-size:13px}.dn{line-height:20px}.dw{padding:0px 8px 1px}.fx{margin-bottom:52px}.gc{padding:0 8px}.gk{margin-bottom:24px}.gl{margin-top:32px}.hc{display:inline-block}.ip{font-size:32px}.iq{margin-top:0.64em}.ir{line-height:40px}.is{letter-spacing:-0.016em}.jm{margin-top:0.46em}.jn{font-size:22px}.jo{line-height:28px}.kf{font-size:18px}.kg{margin-top:1.56em}.kh{letter-spacing:-0.003em}.lb{font-size:20px}.lc{margin-top:1.9em}.ld{line-height:24px}.le{letter-spacing:0}.lq{margin-top:0.67em}.lw{margin-top:40px}.mm{font-size:16px}.mn{margin-top:2.07em}.no{margin-bottom:10px}.od{margin-left:0px}.on{margin-top:0px}.oo{margin-right:0px}.pk{max-height:20px}.qb{margin:0 24px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bt{width:64px}.cf{min-width:0}.cw{padding-left:24px}.cx{display:block}.cy{min-width:352px}.cz{max-width:352px}.ds{font-size:14px}.dt{line-height:20px}.dz{padding:4px 12px 6px}.er{display:flex}.fj{max-width:680px}.ga{margin-bottom:68px}.gf{padding:0 16px}.gq{margin-bottom:24px}.gr{margin-top:32px}.jb{font-size:32px}.jc{margin-top:0.6em}.jd{line-height:40px}.je{letter-spacing:-0.016em}.jv{margin-top:0.79em}.jw{font-size:22px}.jx{line-height:28px}.kp{font-size:20px}.kq{margin-top:2em}.kr{line-height:32px}.ks{letter-spacing:-0.003em}.ll{margin-top:3.14em}.lm{letter-spacing:0}.lt{margin-top:0.86em}.lz{margin-top:56px}.ms{margin-top:2.37em}.mt{line-height:24px}.nr{margin-bottom:26px}.pn{max-height:24px}.qe{margin:0 64px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:flex-end}.bs{width:64px}.cg{min-width:0}.ct{padding-left:24px}.cu{min-width:352px}.cv{max-width:352px}.dq{font-size:13px}.dr{line-height:20px}.dy{padding:0px 8px 1px}.fi{max-width:680px}.fz{margin-bottom:68px}.ge{padding:0 16px}.go{margin-bottom:24px}.gp{margin-top:32px}.he{display:inline-block}.ix{font-size:32px}.iy{margin-top:0.6em}.iz{line-height:40px}.ja{letter-spacing:-0.016em}.js{margin-top:0.79em}.jt{font-size:22px}.ju{line-height:28px}.kl{font-size:20px}.km{margin-top:2em}.kn{line-height:32px}.ko{letter-spacing:-0.003em}.lj{margin-top:3.14em}.lk{letter-spacing:0}.ls{margin-top:0.86em}.ly{margin-top:56px}.mq{margin-top:2.37em}.mr{line-height:24px}.nq{margin-bottom:26px}.pm{max-height:24px}.qd{margin:0 48px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.br{width:24px}.ch{min-width:0}.cq{padding-left:24px}.cr{min-width:352px}.cs{max-width:352px}.do{font-size:13px}.dp{line-height:20px}.dx{padding:0px 8px 1px}.fy{margin-bottom:52px}.gd{padding:0 8px}.gm{margin-bottom:24px}.gn{margin-top:32px}.hd{display:inline-block}.it{font-size:32px}.iu{margin-top:0.64em}.iv{line-height:40px}.iw{letter-spacing:-0.016em}.jp{margin-top:0.46em}.jq{font-size:22px}.jr{line-height:28px}.ki{font-size:18px}.kj{margin-top:1.56em}.kk{letter-spacing:-0.003em}.lf{font-size:20px}.lg{margin-top:1.9em}.lh{line-height:24px}.li{letter-spacing:0}.lr{margin-top:0.67em}.lx{margin-top:40px}.mo{font-size:16px}.mp{margin-top:2.07em}.np{margin-bottom:10px}.oe{margin-left:0px}.pl{max-height:20px}.qc{margin:0 24px}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="print">.ny{display:none}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.fw{max-height:none}</style><style type="text/css" data-fela-rehydration="489" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.mb{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dk af dl bd aj b al am an ao ap aq ar as s u j i d q dh z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Faf816aaea61&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="dj"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="bd b dm dn do dp dq dr ds dt du dv dk"><span><a class="bd b dm dn dw do dp dx dq dr dy ds dt dz du dv ea eb ec ed ee ef eg eh ei ej ek el em eo ep de bk eq" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="av l"><p class="bd b dm dn do dp dq dr ds dt du dv dk"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ad"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as ab" aria-label="Homepage" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="at au"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="av h"><div class="ab aw ax ay az q ba bb"><div class="bk" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bl bm ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" tabindex="0" class="aw bc bd be z bf bg bh bi bj" placeholder="Search Medium" value=""/></div></div></div><div class="h k w er es"><div class="et ab"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_sidenav-----------" rel="noopener follow"><div class="bd b be z dk di eu ab q ev ew"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="dj l">Write</div></div></a></span></div></div><div class="k j i d"><div class="et ab"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="bd b be z dk di eu ab q ev ew"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="et h k j"><div class="ab q"><p class="bd b dm dn do dp dq dr ds dt du dv dk"><span><a class="bd b dm dn dw do dp dx dq dr dy ds dt dz du dv ea eb ec ed ee ef eg eh ei ej ek el em eo ep de bk eq" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="av l"><p class="bd b dm dn do dp dq dr ds dt du dv dk"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="aw ex al ab q an ey ez fa" aria-label="user options menu"><div class="l di"><img alt="" class="l de bw bx by fe" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fb bw l bx by fc n aw fd"></div></div><svg width="12px" height="12px" viewBox="0 0 15 15"><path d="M3.85 5.15a.5.5 0 0 0-.7.7l4.35 4.36 4.35-4.36a.5.5 0 1 0-.7-.7L7.5 8.79 3.85 5.15z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="bz ca l"><div class="ab cb cc"><main class="cd ce cf cg ch ci l cj"><div class="l"><div class="ff l"><div class="ab cl"><div class="fg bf fh fi fj fk"><div class="fl ab q"><div class="fm l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l di"><img alt="Towards Data Science" class="l de bw bx by fe" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="fb bw l bx by fc n aw fd"></div></div></a></div><div class="fn l fo"><div class="bd b be z dk">Published in</div></div><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><p class="bd b be z fp fq fr fs ft fu fv fw bi">Towards Data Science</p></a></div></div></div></div><div class="fx fy fz ga gb l"><div class="ab cl"><div class="fg bf fh fi fj fk"><article><div class="l"><div class="gc gd ge gf gg gh gi bf gj de l"></div><div class="l"><header class="pw-post-byline-header gk gl gm gn go gp gq gr gs gt l"><div class="ab gu gv"><div class="ab"><div class="fm l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="l di"><img alt="Hugo Tessier" class="l de bw gw gx fe" src="https://miro.medium.com/v2/resize:fill:96:96/1*PAy1sna3YNoKY4jQl9znVw.jpeg" width="48" height="48" loading="lazy"/><div class="fb bw l gw gx fc n aw fd"></div></div></a></div><div class="l"><div class="pw-author bd b gy gz bi"><div class="ha ab q"><div><div class="bk" aria-hidden="false"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/@hugo.tessier?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><div class="ab q">Hugo Tessier</div></a></div></div><div class="hb hc hd he i d"><span><a class="bd b dl z eb hf ec ed ee ef eg eh ei ej ek el em eo ep de bk eq" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_page-524f24852f3c----af816aaea61---------------------follow_byline-----------" rel="noopener follow">Follow</a></span></div></div></div><div class="ab q hg"><p class="pw-published-date bd b be z dk"><span>Sep 9, 2021</span></p><div class="hh bk" aria-hidden="true"><span class="l" aria-hidden="true"><span class="bd b be z dk">·</span></span></div><div class="pw-reading-time bd b be z dk">22 min read</div></div></div></div><div class="h k w er es q"><div class="hi l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on twitter"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hi l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on facebook"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hi l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on linkedin"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hm ab q"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="ae eu ag ah ai aj ak hj am an ao ej ho hp hq"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="hn" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div><div><div class="bk" aria-hidden="false"></div></div></div></div><div class="hr s u j i d"><div class="fm l"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=--------------------------bookmark_header-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="ae eu ag hs ai aj ak ht am an ao ej em ab q hu hv hq"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="hn" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg><p class="bd b be z dk">Save</p></button></a></span></div><div class="hw l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on twitter"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M20 5.34c-.67.41-1.4.7-2.18.87a3.45 3.45 0 0 0-5.02-.1 3.49 3.49 0 0 0-1.02 2.47c0 .28.03.54.07.8a9.91 9.91 0 0 1-7.17-3.66 3.9 3.9 0 0 0-.5 1.74 3.6 3.6 0 0 0 1.56 2.92 3.36 3.36 0 0 1-1.55-.44V10c0 1.67 1.2 3.08 2.8 3.42-.3.06-.6.1-.94.12l-.62-.06a3.5 3.5 0 0 0 3.24 2.43 7.34 7.34 0 0 1-4.36 1.49l-.81-.05a9.96 9.96 0 0 0 5.36 1.56c6.4 0 9.91-5.32 9.9-9.9v-.5c.69-.49 1.28-1.1 1.74-1.81-.63.3-1.3.48-2 .56A3.33 3.33 0 0 0 20 5.33" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hw l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on facebook"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 12.04c0-4.3-3.47-7.79-7.75-7.79a7.77 7.77 0 0 0-5.9 12.84 7.77 7.77 0 0 0 4.69 2.63v-5.49h-1.9v-2.2h1.9v-1.62c0-1.88 1.14-2.9 2.8-2.9.8 0 1.49.06 1.69.08v1.97h-1.15c-.91 0-1.1.43-1.1 1.07v1.4h2.17l-.28 2.2h-1.88v5.52a7.77 7.77 0 0 0 6.7-7.71" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="hw l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as" aria-label="Share on linkedin"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M19.75 5.39v13.22a1.14 1.14 0 0 1-1.14 1.14H5.39a1.14 1.14 0 0 1-1.14-1.14V5.39a1.14 1.14 0 0 1 1.14-1.14h13.22a1.14 1.14 0 0 1 1.14 1.14zM8.81 10.18H6.53v7.3H8.8v-7.3zM9 7.67a1.31 1.31 0 0 0-1.3-1.32h-.04a1.32 1.32 0 0 0 0 2.64A1.31 1.31 0 0 0 9 7.71v-.04zm8.46 5.37c0-2.2-1.4-3.05-2.78-3.05a2.6 2.6 0 0 0-2.3 1.18h-.07v-1h-2.14v7.3h2.28V13.6a1.51 1.51 0 0 1 1.36-1.63h.09c.72 0 1.26.45 1.26 1.6v3.91h2.28l.02-4.43z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="l fo"><div><div class="bk" aria-hidden="false"><button class="ae af ag ah ai aj ak al am an ao ap aq ar as"><span class="bk hj hk hl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3.57 14.67c0-.57.13-1.11.38-1.6l.02-.02v-.02l.02-.02c0-.02 0-.02.02-.02.12-.26.3-.52.57-.8L7.78 9v-.02l.01-.02c.44-.41.91-.7 1.44-.85a4.87 4.87 0 0 0-1.19 2.36A5.04 5.04 0 0 0 8 11.6L6.04 13.6c-.19.19-.32.4-.38.65a2 2 0 0 0 0 .9c.08.2.2.4.38.57l1.29 1.31c.27.28.62.42 1.03.42.42 0 .78-.14 1.06-.42l1.23-1.25.79-.78 1.15-1.16c.08-.09.19-.22.28-.4.1-.2.15-.42.15-.67 0-.16-.02-.3-.06-.45l-.02-.02v-.02l-.07-.14s0-.03-.04-.06l-.06-.13-.02-.02c0-.02 0-.03-.02-.05a.6.6 0 0 0-.14-.16l-.48-.5c0-.04.02-.1.04-.15l.06-.12 1.17-1.14.09-.09.56.57c.02.04.08.1.16.18l.05.04.03.06.04.05.03.04.04.06.1.14.02.02c0 .02.01.03.03.04l.1.2v.02c.1.16.2.38.3.68a1 1 0 0 1 .04.25 3.2 3.2 0 0 1 .02 1.33 3.49 3.49 0 0 1-.95 1.87l-.66.67-.97.97-1.56 1.57a3.4 3.4 0 0 1-2.47 1.02c-.97 0-1.8-.34-2.49-1.03l-1.3-1.3a3.55 3.55 0 0 1-1-2.51v-.01h-.02v.02zm5.39-3.43c0-.19.02-.4.07-.63.13-.74.44-1.37.95-1.87l.66-.67.97-.98 1.56-1.56c.68-.69 1.5-1.03 2.47-1.03.97 0 1.8.34 2.48 1.02l1.3 1.32a3.48 3.48 0 0 1 1 2.48c0 .58-.11 1.11-.37 1.6l-.02.02v.02l-.02.04c-.14.27-.35.54-.6.8L16.23 15l-.01.02-.01.02c-.44.42-.92.7-1.43.83a4.55 4.55 0 0 0 1.23-3.52L18 10.38c.18-.21.3-.42.35-.65a2.03 2.03 0 0 0-.01-.9 1.96 1.96 0 0 0-.36-.58l-1.3-1.3a1.49 1.49 0 0 0-1.06-.42c-.42 0-.77.14-1.06.4l-1.2 1.27-.8.8-1.16 1.15c-.08.08-.18.21-.29.4a1.66 1.66 0 0 0-.08 1.12l.02.03v.02l.06.14s.01.03.05.06l.06.13.02.02.01.02.01.02c.05.08.1.13.14.16l.47.5c0 .04-.02.09-.04.15l-.06.12-1.15 1.15-.1.08-.56-.56a2.3 2.3 0 0 0-.18-.19c-.02-.01-.02-.03-.02-.04l-.02-.02a.37.37 0 0 1-.1-.12c-.03-.03-.05-.04-.05-.06l-.1-.15-.02-.02-.02-.04-.08-.17v-.02a5.1 5.1 0 0 1-.28-.69 1.03 1.03 0 0 1-.04-.26c-.06-.23-.1-.46-.1-.7v.01z" fill="#A8A8A8"></path></svg></span></button></div></div></div><div class="bl l"><div><div class="bk" aria-hidden="false"></div></div></div></div></header><span class="l"></span><section><div><div class="fc ib ic id ie if"></div><div class="ig ih ii ij ik"><div class=""><h1 id="06b7" class="pw-post-title il im in bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi">Neural Network Pruning 101</h1></div><div class=""><h2 id="c2f6" class="pw-subtitle-paragraph jk im in bd b jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb dk">All you need to know not to get lost</h2></div><p id="ca09" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.</p><p id="375f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">That is the whole point of neural networks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.</p><p id="24e1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.</p><p id="9a45" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.</p><p id="b038" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “How to prune parts without harming the network?”. To sum it up, we will detail <strong class="ke io">pruning structures</strong>, <strong class="ke io">pruning criteria</strong> and <strong class="ke io">pruning methods</strong>.</p><h1 id="1f16" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">1 — Pruning structures</h1><h1 id="8cb0" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">1.1 — Unstructured pruning</h1><p id="fdc8" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].</p><p id="462b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called <strong class="ke io">unstructured pruning</strong>.</p><p id="67a2" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi lv"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qwYH1r-h6VOGiE6C2tpGg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*7qwYH1r-h6VOGiE6C2tpGg.png 640w, https://miro.medium.com/v2/resize:fit:720/1*7qwYH1r-h6VOGiE6C2tpGg.png 720w, https://miro.medium.com/v2/resize:fit:750/1*7qwYH1r-h6VOGiE6C2tpGg.png 750w, https://miro.medium.com/v2/resize:fit:786/1*7qwYH1r-h6VOGiE6C2tpGg.png 786w, https://miro.medium.com/v2/resize:fit:828/1*7qwYH1r-h6VOGiE6C2tpGg.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*7qwYH1r-h6VOGiE6C2tpGg.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*7qwYH1r-h6VOGiE6C2tpGg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bf mf mg c" width="700" height="414" loading="lazy" role="presentation"/></picture></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)</figcaption></figure><h2 id="01ae" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">1.2 — Structured pruning</h2><p id="d73b" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.</p><p id="4a73" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of <strong class="ke io">structured pruning</strong>.</p><p id="b13b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for <em class="mx">Cin</em> input channels and <em class="mx">Cout</em> output ones, a convolution layer is made of <em class="mx">Cout</em> filters, each counting <em class="mx">Cin</em> kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.</p><p id="920a" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, <strong class="ke io">when pruning filters, one should consider computing the exact number of actually pruned parameters</strong>. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.</p><p id="64ad" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even <a class="ae my" href="https://developer.nvidia.com/blog/accelerating-inference-with-sparsity-using-ampere-and-tensorrt/" rel="noopener ugc nofollow" target="_blank">specific parameter-wise structures</a>. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mz"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*o0Qh-ORMytWTA2xdCFbPiQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*o0Qh-ORMytWTA2xdCFbPiQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*o0Qh-ORMytWTA2xdCFbPiQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*o0Qh-ORMytWTA2xdCFbPiQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*o0Qh-ORMytWTA2xdCFbPiQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*o0Qh-ORMytWTA2xdCFbPiQ.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bf mf mg c" width="700" height="602" loading="lazy" role="presentation"/></picture></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)</figcaption></figure><h1 id="7400" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">2 — Pruning criteria</h1><p id="af47" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.</p><h2 id="a3f6" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">2.1 — Weight magnitude criterion</h2><p id="ab7c" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.</p><p id="b739" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.</p><p id="44f2" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].</p><h2 id="a4d6" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">2.2 — Gradient magnitude pruning</h2><p id="e034" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80&#x27;s some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.</p><p id="50c3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].</p><h2 id="f74e" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">2.3 — Global or local pruning</h2><p id="7f2b" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi na"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rMLCgVa380ZBcgM0Iqg84Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*rMLCgVa380ZBcgM0Iqg84Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*rMLCgVa380ZBcgM0Iqg84Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*rMLCgVa380ZBcgM0Iqg84Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*rMLCgVa380ZBcgM0Iqg84Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*rMLCgVa380ZBcgM0Iqg84Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*rMLCgVa380ZBcgM0Iqg84Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*rMLCgVa380ZBcgM0Iqg84Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bf mf mg c" width="700" height="301" loading="lazy" role="presentation"/></picture></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)</figcaption></figure><h1 id="703c" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">3 — Pruning method</h1><p id="e967" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.</p><p id="7b8d" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.</p><h2 id="45d5" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.1 — The classic framework: train, prune and fine-tune</h2><p id="f197" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.</p><p id="50e4" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.</p><h2 id="62f4" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.2 — Extending the classic framework</h2><p id="3d86" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.</p><p id="67de" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.</p><h2 id="062d" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.3 — Pruning at initialization</h2><p id="6ba9" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].</p><p id="98e1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi nb"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALVyE5U7jC692UGVKCVY8Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*ALVyE5U7jC692UGVKCVY8Q.png 640w, https://miro.medium.com/v2/resize:fit:720/1*ALVyE5U7jC692UGVKCVY8Q.png 720w, https://miro.medium.com/v2/resize:fit:750/1*ALVyE5U7jC692UGVKCVY8Q.png 750w, https://miro.medium.com/v2/resize:fit:786/1*ALVyE5U7jC692UGVKCVY8Q.png 786w, https://miro.medium.com/v2/resize:fit:828/1*ALVyE5U7jC692UGVKCVY8Q.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*ALVyE5U7jC692UGVKCVY8Q.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*ALVyE5U7jC692UGVKCVY8Q.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bf mf mg c" width="700" height="286" loading="lazy" role="presentation"/></picture></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)</figcaption></figure><h2 id="0d30" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.4 — Sparse training</h2><p id="fd21" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called <strong class="ke io">sparse training</strong>, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.</p><p id="4cad" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi na"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hP9xPMOSnsxqtLIvGrhOA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*3hP9xPMOSnsxqtLIvGrhOA.png 640w, https://miro.medium.com/v2/resize:fit:720/1*3hP9xPMOSnsxqtLIvGrhOA.png 720w, https://miro.medium.com/v2/resize:fit:750/1*3hP9xPMOSnsxqtLIvGrhOA.png 750w, https://miro.medium.com/v2/resize:fit:786/1*3hP9xPMOSnsxqtLIvGrhOA.png 786w, https://miro.medium.com/v2/resize:fit:828/1*3hP9xPMOSnsxqtLIvGrhOA.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*3hP9xPMOSnsxqtLIvGrhOA.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*3hP9xPMOSnsxqtLIvGrhOA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bf mf mg c" width="700" height="416" loading="lazy" role="presentation"/></picture></div></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)</figcaption></figure><h2 id="f9f3" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.5 — Mask learning</h2><p id="88ec" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.</p><p id="1475" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter <em class="mx">p</em> that is learned using a “Straight Through Estimator” [3] or other means [44].</p><h2 id="7a36" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">3.6 — Penalty-based methods</h2><p id="b905" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).</p><p id="ba3b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].</p><h1 id="344e" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">4 — Available frameworks</h1><p id="d420" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.</p><h2 id="1145" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">4.1 — Pytorch</h2><p id="9c63" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi"><em class="mx">Pytorch</em> [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.</p><h2 id="3f1c" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">4.2 — Tensorflow</h2><p id="db73" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">The <em class="mx">Keras</em> [10] library from <em class="mx">Tensorflow</em> [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).</p><h2 id="c61c" class="ml kz in bd la mm mn dn le mo mp dp li kl mq mr lk kp ms mt lm kt mu mv lo mw bi">4.3 — ShrinkBench</h2><p id="29c2" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on <em class="mx">Pytorch</em>, <em class="mx">ShrinkBench</em> aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.</p><h1 id="0db7" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">5 — Brief recap of reviewed methods</h1><p id="4f0a" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):</p><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="nc nd l"></div></div></figure><h1 id="5fc5" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">6 — Conclusion</h1><p id="dbd7" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.</p><p id="8cda" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”</p><h1 id="b0a7" class="ky kz in bd la lb lc ld le lf lg lh li jt lj ju lk jw ll jx lm jz ln ka lo lp bi">References</h1><p id="333c" class="pw-post-body-paragraph kc kd in ke b kf lq jo kh ki lr jr kk kl ls kn ko kp lt kr ks kt lu kv kw kx ig bi">[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.</p><p id="1fba" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.</p><p id="9ab6" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.</p><p id="4225" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.</p><p id="1893" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.</p><p id="4edf" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.</p><p id="5a92" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1/2 penalty. IEEE Access, 7:2273–2280, 2018.</p><p id="7d74" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.</p><p id="2b0e" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.</p><p id="5860" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[10] Francois Chollet et al. Keras, 2015.</p><p id="a78f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.</p><p id="f314" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.</p><p id="5849" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.</p><p id="2aed" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.</p><p id="eb74" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.</p><p id="b415" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.</p><p id="f184" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.</p><p id="bf6f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.</p><p id="3617" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.</p><p id="58c0" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.</p><p id="4f5f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.</p><p id="74d8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops, pages 0–0, 2019.</p><p id="a37e" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.</p><p id="771a" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.</p><p id="c933" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.</p><p id="a6e9" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.</p><p id="3b8d" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.</p><p id="ff92" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.</p><p id="9f85" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.</p><p id="14d2" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.</p><p id="af2f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.</p><p id="7371" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.</p><p id="55ce" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.</p><p id="3f8f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.</p><p id="93d7" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.</p><p id="38d1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.</p><p id="1b89" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.</p><p id="b9d6" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.</p><p id="c8c3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.</p><p id="fa53" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.</p><p id="5975" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.</p><p id="3879" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.</p><p id="8d02" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.</p><p id="eb44" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.</p><p id="4866" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.</p><p id="235f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.</p><p id="6721" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.</p><p id="2a85" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.</p><p id="9f44" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.</p><p id="1ef1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.</p><p id="aa9b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.</p><p id="79eb" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.</p><p id="ce0a" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.</p><p id="d3f1" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.</p><p id="bc88" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.</p><p id="b046" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.</p><p id="d7b3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.</p><p id="3bf3" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.</p><p id="3d25" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="5eb0" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.</p><p id="5fd8" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.</p><p id="1d5f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.</p><p id="44d2" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.</p><p id="1727" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.</p><p id="c94b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.</p><p id="ce36" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.</p><p id="45b5" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.</p><p id="8e2b" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.</p><p id="7479" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.</p><p id="726f" class="pw-post-body-paragraph kc kd in ke b kf kg jo kh ki kj jr kk kl km kn ko kp kq kr ks kt ku kv kw kx ig bi">[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.</p></div></div></section></div></div></article></div></div></div><div class="ab cl"><div class="fg bf fh fi fj fk"><div class="ne nf ab hg"><div class="ng ab"><a class="nh aw al an" href="https://medium.com/tag/neural-networks?source=post_page-----af816aaea61---------------neural_networks-----------------" rel="noopener follow"><div class="ni di fe nj nk nl bd b be z bi nm">Neural Networks</div></a></div><div class="ng ab"><a class="nh aw al an" href="https://medium.com/tag/pruning?source=post_page-----af816aaea61---------------pruning-----------------" rel="noopener follow"><div class="ni di fe nj nk nl bd b be z bi nm">Pruning</div></a></div><div class="ng ab"><a class="nh aw al an" href="https://medium.com/tag/compression?source=post_page-----af816aaea61---------------compression-----------------" rel="noopener follow"><div class="ni di fe nj nk nl bd b be z bi nm">Compression</div></a></div><div class="ng ab"><a class="nh aw al an" href="https://medium.com/tag/deep-learning?source=post_page-----af816aaea61---------------deep_learning-----------------" rel="noopener follow"><div class="ni di fe nj nk nl bd b be z bi nm">Deep Learning</div></a></div><div class="ng ab"><a class="nh aw al an" href="https://medium.com/tag/deep-dives?source=post_page-----af816aaea61---------------deep_dives-----------------" rel="noopener follow"><div class="ni di fe nj nk nl bd b be z bi nm">Deep Dives</div></a></div></div></div></div><div class="l"></div><footer class="nn no np nq nr ns nt nu nv ab q nw nx c"><div class="l ad"><div class="ab cl"><div class="fg bf fh fi fj fk"><div class="ab gv ny"><div class="ab q cb"><div class="nz l"><span class="l hc oa ob e d"><div class="ab q cb"><div class="pw-multi-vote-icon di oc od oe of"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------clap_footer-----------" rel="noopener follow"><div class="og an eu oh oi oj al ok ol om of"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l on oo op oq or os ot"><p class="bd b dl z dk"><span class="ou">--</span></p></div></div></span><span class="l h g f ov ow"><div class="ab q cb"><div class="pw-multi-vote-icon di oc od oe of"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=-----af816aaea61---------------------clap_footer-----------" rel="noopener follow"><div class="og an eu oh oi oj al ok ol om of"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l on oo op oq or os ot"><p class="bd b dl z dk"><span class="ou">--</span></p></div></div></span></div><div class="bo ab"><div><div class="bk" aria-hidden="false"><button class="an og oy oz ab q eu oi pa" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="responses" class="ox"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="bd b be z dk"><span class="pw-responses-count pb ox">2</span></p></button></div></div></div></div><div class="ab q"><div class="bk" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bk" aria-hidden="false"><button class="ae eu ag ah ai aj ak hj am an ao ej pc pd pa pe"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div><div class="pf pg l fo"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="ae eu ag ah ai aj ak hj am an ao ej ho hp hq"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="hn" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div></div></div></div></footer><div class="ab cl"><div class="fg bf fh fi fj fk"></div></div><div class="l"><div class="l bv ny"><div class="l ny"><div class="ph pi l bv"><div class="ab cl"><div class="fg bf fh fi fj fk"><div class="ab q gv"><h2 class="bd pj mm dn pk le mo dp pl li kl mr pm lk kp mt pn lm kt mv po lo fp fr fs ft fu fv fw bi"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">More from Towards Data Science</a></h2><span><a class="bd b be z eb pp ec ed ee ef eg eh ei ej ek el em eo ep de bk eq" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fcollection%2Ftowards-data-science%2Faf816aaea61&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;collection=Towards+Data+Science&amp;collectionId=7f60cf5620c9&amp;source=post_page-----af816aaea61---------------------follow_footer-----------" rel="noopener follow">Follow</a></span></div><div class="pq l ig"><p class="bd b be z dk">Your home for data science. A Medium publication sharing concepts, ideas and codes.</p></div></div></div></div></div><div class="pr l"><div class="ps pt l"><div class="mf l mi"><a class="bd b be z eb pp ec ed ee ef eg eh ei ej ek el em eo ep de bk eq" href="https://towardsdatascience.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">Read more from <!-- -->Towards Data Science</a></div></div></div></div></div><div class="d"><div class="pu pv pw l nw px py ib pz qa"><div class="ab cl"><div class="qb qc qd qe qf qg fg bf"><a class="ae af ag ah ai aj ak al am an ao qh qi qj qk" aria-label="Go to homepage" href="https://medium.com/?source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><svg viewBox="0 0 3940 610" class="ec ql"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="qm l"><p class="bd b dl z qn"><a class="ae af ag ah ai aj ak al am an ao qh qi qo pg" href="https://medium.com/about?autoplay=1&amp;source=post_page-----af816aaea61--------------------------------" rel="noopener follow">About</a><a class="ae af ag ah ai aj ak al am an ao qh qi qo pg" href="https://help.medium.com/hc/en-us?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">Help</a><a class="ae af ag ah ai aj ak al am an ao qh qi qo pg" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">Terms</a><a class="ae af ag ah ai aj ak al am an ao qh qi qo" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----af816aaea61--------------------------------" rel="noopener follow">Privacy</a></p></div><div class="j i d"><hr class="og qp qq qr" aria-hidden="true"/><h2 class="bd pj gy z im qn">Get the Medium app</h2><div class="qm ab"><div class="fm l"><a class="ae af ag ah ai aj ak al am an ao qh qi qj qk" href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><img alt="A button that says &#x27;Download on the App Store&#x27;, and if clicked it will lead you to the iOS App store" class="" src="https://miro.medium.com/v2/resize:fit:270/1*Crl55Tm6yDNMoucPo1tvDg.png" width="135" height="41" loading="lazy"/></a></div><a class="ae af ag ah ai aj ak al am an ao qh qi qj qk" href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----af816aaea61--------------------------------" rel="noopener follow"><img alt="A button that says &#x27;Get it on, Google Play&#x27;, and if clicked it will lead you to the Google Play store" class="" src="https://miro.medium.com/v2/resize:fit:270/1*W_RAPQ62h0em559zluJLdQ.png" width="135" height="41" loading="lazy"/></a></div></div></div></div></div></div></div></main><div class="cm cn h co cp cq k cr cs ct j cu cv cw cx cy cz da db dc dd de c df dg"><div class="dh bf bk di"><div class="l m qs"><div class="qt ab qu"><div class="l ad"><div class="qv qw qx l"></div><div class="qv qw qx l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/@hugo.tessier?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><div class="l di"><img alt="Hugo Tessier" class="l de bw qy qz fe" src="https://miro.medium.com/v2/resize:fill:176:176/1*PAy1sna3YNoKY4jQl9znVw.jpeg" width="88" height="88" loading="lazy"/><div class="fb bw l qy qz fc n aw fd"></div></div></a><div class="ra l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/@hugo.tessier?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><h2 class="pw-author-name bd pj gy z im bi"><span class="ig">Hugo Tessier</span></h2></a></div><div class="rb l"><span class="pw-follower-count bd b gy gz dk"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/@hugo.tessier/followers?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow">51 Followers</a></span></div><div class="rc l"><p class="bd b be z dk"><span class="ig">PHD student in deep learning, working on neural network compression and, especially, pruning.</span></p></div><div class="rd re ab"><span><a class="bd b be z eb pp ec ed ee ef eg eh ei ej ek el em rf eo ep de bk eq" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F524f24852f3c&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=post_page-524f24852f3c--two_column_layout_sidebar-----------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="dj l"><div><div><div class="bk" aria-hidden="false"><div class="l"><span><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F71cc63d0ec07&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fneural-network-pruning-101-af816aaea61&amp;newsletterV3=524f24852f3c&amp;newsletterV3Id=71cc63d0ec07&amp;user=Hugo+Tessier&amp;userId=524f24852f3c&amp;source=---two_column_layout_sidebar-----------------------subscribe_user-----------" rel="noopener follow"><button class="bd b be z rj al rk rl rm rn ro rp rq rr ei ej ek el em eo ep de bk eq" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="rg rh ri"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div><div class="qv qw qx l"></div><div class="qv qw qx l"></div></div><div class="rs ab cb hg"><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://help.medium.com/hc/en-us?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Help</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.statuspage.io/?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Status</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://about.medium.com/creators/?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Writers</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://blog.medium.com/?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Blog</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Careers</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Privacy</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Terms</p></a></div><div class="rt l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://medium.com/about?autoplay=1&amp;source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">About</p></a></div><div class="l"><a class="ae af ag ah ai aj ak al am an ao ap aq ar as" href="https://speechify.com/medium?source=---two_column_layout_sidebar----------------------------------" rel="noopener follow"><p class="bd b ru rv dk">Text to speech</p></a></div></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20230421-214048-7306d1f6f5"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"auroraPage":{"isAuroraPageEnabled":false},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-af816aaea61","user-524f24852f3c","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"inDisabledExperiment":false,"postPageSingleColumnLayoutEnabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"df005d5c-ceca-4090-80ba-971dbdb201b2","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"003e79f804aac637","ot-tracer-traceid":"525916f710f1872b","ot-tracer-sampled":"true"}},"meter":{},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20230421-214048-7306d1f6f5","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20230421-214048-7306d1f6f5","commit":"7306d1f6f5ce60ae80d7e7bf11ee6d8168704648"}},"datacenter":"us"},"googleAnalyticsCode":"UA-24232453-2","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"explicit_signals_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_incognito_regwall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_notifications_rewrite","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_responses_rewrite","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_nav","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_deprecate_custom_profile","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"explicit_signals_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"bevy_rds_double_write","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"author_fair_distribution_non_qp3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_boosted_notification","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_edge_cache","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_featurestore_parallel_queries","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_notifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_generation_pipeline","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"af816aaea61\"})":{"__ref":"Post:af816aaea61"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"domain":"towardsdatascience.com","name":"Towards Data Science","slug":"towards-data-science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"isAuroraVisible":true,"legacyHeaderBackgroundImage":null,"logo":{"__ref":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"},"subscriberCount":659596,"newsletterV3":{"__ref":"NewsletterV3:d6fe9076899"},"navItems":[{"__typename":"NavItem","tagSlug":null,"title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"★","url":"https:\u002F\u002Ftowardsdatascience.com\u002Feditors-picks\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome"},{"__typename":"NavItem","tagSlug":null,"title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome"}],"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_a4e000747f83"},"twitterUsername":"TDataScience","facebookPageId":null,"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","status":"ACTIVE","isSubdomain":false}},"creator":{"__ref":"User:7e12c71dfa81"},"ptsQualifiedAt":1616092952992,"description":"Your home for data science. A Medium publication sharing concepts, ideas and codes."},"CustomStyleSheet:514038af8f2f":{"__typename":"CustomStyleSheet","id":"514038af8f2f","global":{"__typename":"GlobalStyles","colorPalette":{"__typename":"StyleSheetColorPalette","primary":{"__typename":"ColorValue","colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}}},"background":null},"fonts":{"__typename":"StyleSheetFonts","font1":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font2":{"__typename":"StyleSheetFont","name":"SANS_SERIF_1"},"font3":{"__typename":"StyleSheetFont","name":"SERIF_2"}}},"header":{"__typename":"HeaderStyles","headerScale":"HEADER_SCALE_MEDIUM","backgroundImageDisplayMode":"IMAGE_DISPLAY_MODE_FILL","backgroundImageVerticalAlignment":"CENTER","backgroundColorDisplayMode":"COLOR_DISPLAY_MODE_SOLID","backgroundColor":{"__typename":"ColorValue","alpha":"59","rgb":"355876"},"secondaryBackgroundColor":null,"postBackgroundColor":null,"backgroundImage":{"__ref":"ImageMetadata:1*Pxg5mSUxMauqJj07YJmtdg.png"},"logoImage":{"__ref":"ImageMetadata:1*jGgIXzQHi3stXYzPKNA6Qg.png"},"appNameColor":null,"appNameTreatment":"NAME_TREATMENT_LOGO","nameTreatment":"NAME_TREATMENT_LOGO"},"navigation":{"__typename":"HeaderNavigation","navItems":[{"__typename":"HeaderNavigationItem","name":"Editors' Picks","href":null,"tags":[{"__ref":"Tag:editors-pick"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Features","href":null,"tags":[{"__ref":"Tag:tds-features"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Deep Dives","href":null,"tags":[{"__ref":"Tag:deep-dives"}],"type":"NAV_TYPE_TAG"},{"__typename":"HeaderNavigationItem","name":"Author Resources","href":"https:\u002F\u002Ftowardsdatascience.com\u002Fquestions-96667b06af5","tags":[],"type":"NAV_TYPE_LINK"}]}},"UserViewerEdge:userId:524f24852f3c-viewerId:lo_a4e000747f83":{"__typename":"UserViewerEdge","isBlocking":false,"id":"userId:524f24852f3c-viewerId:lo_a4e000747f83","isFollowing":false,"isUser":false},"NewsletterV3:71cc63d0ec07":{"__typename":"NewsletterV3","id":"71cc63d0ec07","type":"NEWSLETTER_TYPE_AUTHOR","slug":"524f24852f3c","name":"524f24852f3c","collection":null,"user":{"__ref":"User:524f24852f3c"},"description":"","promoHeadline":"","promoBody":"","showPromo":false},"User:524f24852f3c":{"__typename":"User","id":"524f24852f3c","name":"Hugo Tessier","username":"hugo.tessier","newsletterV3":{"__ref":"NewsletterV3:71cc63d0ec07"},"imageId":"1*PAy1sna3YNoKY4jQl9znVw.jpeg","socialStats":{"__typename":"SocialStats","followerCount":51,"followingCount":1,"collectionFollowingCount":0},"customStyleSheet":null,"viewerEdge":{"__ref":"UserViewerEdge:userId:524f24852f3c-viewerId:lo_a4e000747f83"},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"PHD student in deep learning, working on neural network compression and, especially, pruning.","isPartnerProgramEnrolled":false,"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"authoredBooks":[],"linkedAccounts":{"__ref":"LinkedAccounts:524f24852f3c"},"mediumMemberAt":0,"homepagePostsConnection:{\"paging\":{\"limit\":1}}":{"__typename":"PostConnection","posts":[{"__ref":"Post:af816aaea61"}]},"isSuspended":false,"allowNotes":true,"twitterScreenName":"","atsQualifiedAt":1631610169172,"isAuroraVisible":true},"Post:af816aaea61":{"__typename":"Post","id":"af816aaea61","firstPublishedAt":1631169416338,"visibility":"PUBLIC","creator":{"__ref":"User:524f24852f3c"},"canonicalUrl":"","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{\"forceTruncation\":false}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"validatedShareKey":"","bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"7520","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:58956a883341_0"},{"__ref":"Paragraph:58956a883341_1"},{"__ref":"Paragraph:58956a883341_2"},{"__ref":"Paragraph:58956a883341_3"},{"__ref":"Paragraph:58956a883341_4"},{"__ref":"Paragraph:58956a883341_5"},{"__ref":"Paragraph:58956a883341_6"},{"__ref":"Paragraph:58956a883341_7"},{"__ref":"Paragraph:58956a883341_8"},{"__ref":"Paragraph:58956a883341_9"},{"__ref":"Paragraph:58956a883341_10"},{"__ref":"Paragraph:58956a883341_11"},{"__ref":"Paragraph:58956a883341_12"},{"__ref":"Paragraph:58956a883341_13"},{"__ref":"Paragraph:58956a883341_14"},{"__ref":"Paragraph:58956a883341_15"},{"__ref":"Paragraph:58956a883341_16"},{"__ref":"Paragraph:58956a883341_17"},{"__ref":"Paragraph:58956a883341_18"},{"__ref":"Paragraph:58956a883341_19"},{"__ref":"Paragraph:58956a883341_20"},{"__ref":"Paragraph:58956a883341_21"},{"__ref":"Paragraph:58956a883341_22"},{"__ref":"Paragraph:58956a883341_23"},{"__ref":"Paragraph:58956a883341_24"},{"__ref":"Paragraph:58956a883341_25"},{"__ref":"Paragraph:58956a883341_26"},{"__ref":"Paragraph:58956a883341_27"},{"__ref":"Paragraph:58956a883341_28"},{"__ref":"Paragraph:58956a883341_29"},{"__ref":"Paragraph:58956a883341_30"},{"__ref":"Paragraph:58956a883341_31"},{"__ref":"Paragraph:58956a883341_32"},{"__ref":"Paragraph:58956a883341_33"},{"__ref":"Paragraph:58956a883341_34"},{"__ref":"Paragraph:58956a883341_35"},{"__ref":"Paragraph:58956a883341_36"},{"__ref":"Paragraph:58956a883341_37"},{"__ref":"Paragraph:58956a883341_38"},{"__ref":"Paragraph:58956a883341_39"},{"__ref":"Paragraph:58956a883341_40"},{"__ref":"Paragraph:58956a883341_41"},{"__ref":"Paragraph:58956a883341_42"},{"__ref":"Paragraph:58956a883341_43"},{"__ref":"Paragraph:58956a883341_44"},{"__ref":"Paragraph:58956a883341_45"},{"__ref":"Paragraph:58956a883341_46"},{"__ref":"Paragraph:58956a883341_47"},{"__ref":"Paragraph:58956a883341_48"},{"__ref":"Paragraph:58956a883341_49"},{"__ref":"Paragraph:58956a883341_50"},{"__ref":"Paragraph:58956a883341_51"},{"__ref":"Paragraph:58956a883341_52"},{"__ref":"Paragraph:58956a883341_53"},{"__ref":"Paragraph:58956a883341_54"},{"__ref":"Paragraph:58956a883341_55"},{"__ref":"Paragraph:58956a883341_56"},{"__ref":"Paragraph:58956a883341_57"},{"__ref":"Paragraph:58956a883341_58"},{"__ref":"Paragraph:58956a883341_59"},{"__ref":"Paragraph:58956a883341_60"},{"__ref":"Paragraph:58956a883341_61"},{"__ref":"Paragraph:58956a883341_62"},{"__ref":"Paragraph:58956a883341_63"},{"__ref":"Paragraph:58956a883341_64"},{"__ref":"Paragraph:58956a883341_65"},{"__ref":"Paragraph:58956a883341_66"},{"__ref":"Paragraph:58956a883341_67"},{"__ref":"Paragraph:58956a883341_68"},{"__ref":"Paragraph:58956a883341_69"},{"__ref":"Paragraph:58956a883341_70"},{"__ref":"Paragraph:58956a883341_71"},{"__ref":"Paragraph:58956a883341_72"},{"__ref":"Paragraph:58956a883341_73"},{"__ref":"Paragraph:58956a883341_74"},{"__ref":"Paragraph:58956a883341_75"},{"__ref":"Paragraph:58956a883341_76"},{"__ref":"Paragraph:58956a883341_77"},{"__ref":"Paragraph:58956a883341_78"},{"__ref":"Paragraph:58956a883341_79"},{"__ref":"Paragraph:58956a883341_80"},{"__ref":"Paragraph:58956a883341_81"},{"__ref":"Paragraph:58956a883341_82"},{"__ref":"Paragraph:58956a883341_83"},{"__ref":"Paragraph:58956a883341_84"},{"__ref":"Paragraph:58956a883341_85"},{"__ref":"Paragraph:58956a883341_86"},{"__ref":"Paragraph:58956a883341_87"},{"__ref":"Paragraph:58956a883341_88"},{"__ref":"Paragraph:58956a883341_89"},{"__ref":"Paragraph:58956a883341_90"},{"__ref":"Paragraph:58956a883341_91"},{"__ref":"Paragraph:58956a883341_92"},{"__ref":"Paragraph:58956a883341_93"},{"__ref":"Paragraph:58956a883341_94"},{"__ref":"Paragraph:58956a883341_95"},{"__ref":"Paragraph:58956a883341_96"},{"__ref":"Paragraph:58956a883341_97"},{"__ref":"Paragraph:58956a883341_98"},{"__ref":"Paragraph:58956a883341_99"},{"__ref":"Paragraph:58956a883341_100"},{"__ref":"Paragraph:58956a883341_101"},{"__ref":"Paragraph:58956a883341_102"},{"__ref":"Paragraph:58956a883341_103"},{"__ref":"Paragraph:58956a883341_104"},{"__ref":"Paragraph:58956a883341_105"},{"__ref":"Paragraph:58956a883341_106"},{"__ref":"Paragraph:58956a883341_107"},{"__ref":"Paragraph:58956a883341_108"},{"__ref":"Paragraph:58956a883341_109"},{"__ref":"Paragraph:58956a883341_110"},{"__ref":"Paragraph:58956a883341_111"},{"__ref":"Paragraph:58956a883341_112"},{"__ref":"Paragraph:58956a883341_113"},{"__ref":"Paragraph:58956a883341_114"},{"__ref":"Paragraph:58956a883341_115"},{"__ref":"Paragraph:58956a883341_116"},{"__ref":"Paragraph:58956a883341_117"},{"__ref":"Paragraph:58956a883341_118"},{"__ref":"Paragraph:58956a883341_119"},{"__ref":"Paragraph:58956a883341_120"},{"__ref":"Paragraph:58956a883341_121"},{"__ref":"Paragraph:58956a883341_122"},{"__ref":"Paragraph:58956a883341_123"},{"__ref":"Paragraph:58956a883341_124"},{"__ref":"Paragraph:58956a883341_125"},{"__ref":"Paragraph:58956a883341_126"},{"__ref":"Paragraph:58956a883341_127"},{"__ref":"Paragraph:58956a883341_128"},{"__ref":"Paragraph:58956a883341_129"},{"__ref":"Paragraph:58956a883341_130"},{"__ref":"Paragraph:58956a883341_131"},{"__ref":"Paragraph:58956a883341_132"},{"__ref":"Paragraph:58956a883341_133"},{"__ref":"Paragraph:58956a883341_134"},{"__ref":"Paragraph:58956a883341_135"},{"__ref":"Paragraph:58956a883341_136"},{"__ref":"Paragraph:58956a883341_137"},{"__ref":"Paragraph:58956a883341_138"},{"__ref":"Paragraph:58956a883341_139"}]}},"customStyleSheet":{"__ref":"CustomStyleSheet:514038af8f2f"},"isPublished":true,"isLocked":false,"license":"ALL_RIGHTS_RESERVED","collaborators":[{"__ref":"Collaborator:af816aaea61-a71060a2ef24"}],"statusForCollection":"APPROVED","isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fneural-network-pruning-101-af816aaea61","primaryTopic":{"__ref":"Topic:ae5d4995e225"},"topics":[{"__typename":"Topic","slug":"machine-learning","name":"Machine Learning"},{"__typename":"Topic","slug":"data-science","name":"Data Science"}],"viewerEdge":{"__ref":"PostViewerEdge:postId:af816aaea61-viewerId:lo_a4e000747f83"},"latestPublishedVersion":"58956a883341","postResponses":{"__typename":"PostResponses","count":2},"allowResponses":true,"isLimitedState":false,"voterCount":87,"recommenders":[],"isSeries":false,"sequence":null,"uniqueSlug":"neural-network-pruning-101-af816aaea61","title":"Neural Network Pruning 101","clapCount":402,"layerCake":3,"tags":[{"__ref":"Tag:neural-networks"},{"__ref":"Tag:pruning"},{"__ref":"Tag:compression"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:deep-dives"}],"readingTime":21.278616352201258,"pendingCollection":null,"inResponseToEntityType":null,"socialTitle":"","socialDek":"","noIndex":null,"curationStatus":"CURATION_STATUS_DISTRIBUTED","metaDescription":"","latestPublishedAt":1631519525992,"previewContent":{"__typename":"PreviewContent","subtitle":"All you need to know not to get lost"},"previewImage":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"isShortform":false,"seoTitle":"","updatedAt":1659097889365,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isIndexable":true,"isSuspended":false,"pinnedAt":0,"awards:countToShowAwardBadge(type:STAFF_PICK,limit:1)":{"__typename":"AwardConnection","totalCount":0,"awards":[]}},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"ImageMetadata:1*Pxg5mSUxMauqJj07YJmtdg.png":{"__typename":"ImageMetadata","id":"1*Pxg5mSUxMauqJj07YJmtdg.png","originalWidth":2569},"ImageMetadata:1*jGgIXzQHi3stXYzPKNA6Qg.png":{"__typename":"ImageMetadata","id":"1*jGgIXzQHi3stXYzPKNA6Qg.png","originalHeight":429,"originalWidth":1376},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"__typename":"ImageMetadata","id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalHeight":122,"originalWidth":337},"NewsletterV3:d6fe9076899":{"__typename":"NewsletterV3","slug":"the-variable","id":"d6fe9076899","name":"The Variable","description":"Every Thursday, the Variable delivers the very best of Towards Data Science: from hands-on tutorials and cutting-edge research to original features you don't want to miss.","promoHeadline":"","promoBody":"","type":"NEWSLETTER_TYPE_COLLECTION","user":{"__ref":"User:895063a310f4"},"collection":{"__ref":"Collection:7f60cf5620c9"},"showPromo":true},"Tag:editors-pick":{"__typename":"Tag","id":"editors-pick","normalizedTagSlug":"editors-pick"},"Tag:tds-features":{"__typename":"Tag","id":"tds-features","normalizedTagSlug":"tds-features"},"Tag:deep-dives":{"__typename":"Tag","id":"deep-dives","normalizedTagSlug":"deep-dives","displayTitle":"Deep Dives"},"LinkedAccounts:524f24852f3c":{"__typename":"LinkedAccounts","mastodon":null,"id":"524f24852f3c"},"Collaborator:af816aaea61-a71060a2ef24":{"__typename":"Collaborator","id":"af816aaea61-a71060a2ef24"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4","name":"Ludovic Benistant","username":"ludobenistant","newsletterV3":{"__ref":"NewsletterV3:2375c85c8da7"}},"NewsletterV3:2375c85c8da7":{"__typename":"NewsletterV3","id":"2375c85c8da7"},"Topic:ae5d4995e225":{"__typename":"Topic","slug":"data-science","id":"ae5d4995e225","name":"Data Science"},"PostViewerEdge:postId:af816aaea61-viewerId:lo_a4e000747f83":{"__typename":"PostViewerEdge","paywall":{"__typename":"PostPaywall","type":"PROGRAMMING","creatorSpotlights":[{"__typename":"CreatorSpotlight","name":"Marc-André Giroux","title":"Sr. Software Developer","company":"Netflix","miroId":"1*uSxyStPJhzmIp7PjJLcpiw.jpeg","hideOnSmallScreen":true},{"__typename":"CreatorSpotlight","name":"Carlos Arguelles","title":"Sr. Staff Engineer","company":"Google","miroId":"1*CM27oO9pXETXjs2M9_dUFg.jpeg","hideOnSmallScreen":null},{"__typename":"CreatorSpotlight","name":"Tony Yiu","title":"Director","company":"Nasdaq","miroId":"2*CSDritfpmHLYxn63arD9sQ.jpeg","hideOnSmallScreen":null},{"__typename":"CreatorSpotlight","name":"Brandeis Marshall","title":"CEO","company":"DataedX","miroId":"1*qLWny7soUL4K4lqhX1wQVw.png","hideOnSmallScreen":null},{"__typename":"CreatorSpotlight","name":"Cassie Kozyrkov","title":"Chief Decision Scientist","company":"Google","miroId":"1*IL0mnvzNcpG2ZD0JBqo7zQ.jpeg","hideOnSmallScreen":true},{"__typename":"CreatorSpotlight","name":"Memo Akten","title":"Asst. Professor","company":"UCSD","miroId":"4*f7EyGRullh3Ih_2tm3k5xw.png","hideOnSmallScreen":null},{"__typename":"CreatorSpotlight","name":"Vitali Zaidman","title":"Software Architect","company":"Meta","miroId":"2*gHhbmOgQGWxZrqDIfLps6A.jpeg","hideOnSmallScreen":null},{"__typename":"CreatorSpotlight","name":"Camille Fournier","title":"Head of Engineering","company":"JPMorgan Chase","miroId":"1*J2fWNTyPbgEhIyvVIjHAXg.jpeg","hideOnSmallScreen":null}]},"id":"postId:af816aaea61-viewerId:lo_a4e000747f83"},"Paragraph:58956a883341_0":{"__typename":"Paragraph","id":"58956a883341_0","name":"06b7","type":"H3","href":null,"layout":null,"metadata":null,"text":"Neural Network Pruning 101","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_1":{"__typename":"Paragraph","id":"58956a883341_1","name":"c2f6","type":"H4","href":null,"layout":null,"metadata":null,"text":"All you need to know not to get lost","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_2":{"__typename":"Paragraph","id":"58956a883341_2","name":"ca09","type":"P","href":null,"layout":null,"metadata":null,"text":"Whether it is in computer vision, natural language processing or image generation, deep neural networks yield the state of the art. However, their cost in terms of computational power, memory or energy consumption can be prohibitive, making some of them downright unaffordable for most limited hardware. Yet, many domains would benefit from neural networks, hence the need to reduce their cost while maintaining their performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_3":{"__typename":"Paragraph","id":"58956a883341_3","name":"375f","type":"P","href":null,"layout":null,"metadata":null,"text":"That is the whole point of neural networks compression. This field counts multiple families of methods, such as quantization [11], factorization [13], distillation [32] or, and this will be the focus of this post, pruning.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_4":{"__typename":"Paragraph","id":"58956a883341_4","name":"24e1","type":"P","href":null,"layout":null,"metadata":null,"text":"Neural network pruning is a method that revolves around the intuitive idea of removing superfluous parts of a network that performs well but costs a lot of resources. Indeed, even though large neural networks have proven countless times how well they could learn, it turns out that not all of their parts are still useful after the training process is over. The idea is to eliminate these parts without impacting the network’s performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_5":{"__typename":"Paragraph","id":"58956a883341_5","name":"9a45","type":"P","href":null,"layout":null,"metadata":null,"text":"Unfortunately, the dozens, if not hundreds, of papers published each year are revealing the hidden complexity of a supposedly straight-forward idea. Indeed, a quick overview of the literature yields countless ways of identifying said useless parts or removing them before, during or after training; it even turns out that not all kinds of pruning actually allow for accelerating neural networks, which is supposed to be the whole point.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_6":{"__typename":"Paragraph","id":"58956a883341_6","name":"b038","type":"P","href":null,"layout":null,"metadata":null,"text":"The goal of this post is to provide a solid foundation to tackle the intimidatingly wild literature around neural network pruning. We will review successively three questions that seem to be at the core of the whole domain: “What kind of part should I prune?”, “How to tell which parts can be pruned?” and “How to prune parts without harming the network?”. To sum it up, we will detail pruning structures, pruning criteria and pruning methods.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":386,"end":404,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":406,"end":422,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":427,"end":442,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_7":{"__typename":"Paragraph","id":"58956a883341_7","name":"1f16","type":"H3","href":null,"layout":null,"metadata":null,"text":"1 — Pruning structures","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_8":{"__typename":"Paragraph","id":"58956a883341_8","name":"8cb0","type":"H3","href":null,"layout":null,"metadata":null,"text":"1.1 — Unstructured pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_9":{"__typename":"Paragraph","id":"58956a883341_9","name":"fdc8","type":"P","href":null,"layout":null,"metadata":null,"text":"When talking about the cost of neural networks, the count of parameters is surely one of the most widely used metrics, along with FLOPS (floating-point operations per second). It is indeed intimidating to see networks displaying astronomical amounts of weights (up to billions for some), often correlated with stellar performance. Therefore, it is quite intuitive to aim at reducing directly this count by removing parameters themselves. Actually, pruning connections is one of the most widespread paradigms in the literature, enough to be considered as the default framework when dealing with pruning. The seminal work of Han et al.[26] presented this kind of pruning and served as a basis for numerous contributions [18, 21, 25].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_10":{"__typename":"Paragraph","id":"58956a883341_10","name":"462b","type":"P","href":null,"layout":null,"metadata":null,"text":"Directly pruning parameters has many advantages. First, it is simple, since replacing the value of their weight with zero, within the parameter tensors, is enough to prune a connection. Widespread deep learning frameworks, such as Pytorch, allow to easily access all the parameters of a network, making it extremely simple to implement. Still, the greatest advantage of pruning connections remains yet that they are the smallest, most fundamental elements of networks and, therefore, they are numerous enough to prune them in large quantities without impacting performance. Such a fine granularity allows pruning very subtle patterns, up to parameters within convolution kernels, for example. As pruning weights is not limited by any constraint at all and is the finest way to prune a network, such a paradigm is called unstructured pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":820,"end":840,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_11":{"__typename":"Paragraph","id":"58956a883341_11","name":"67a2","type":"P","href":null,"layout":null,"metadata":null,"text":"However, this method presents a major, fatal drawback: most frameworks and hardware cannot accelerate sparse matrices’ computation, meaning that no matter how many zeros you fill the parameter tensors with, it will not impact the actual cost of the network. What does impact it, however, is pruning in a way that directly alters the very architecture of the network, which any framework can handle.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png":{"__typename":"ImageMetadata","id":"1*7qwYH1r-h6VOGiE6C2tpGg.png","originalHeight":1436,"originalWidth":2430,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_12":{"__typename":"Paragraph","id":"58956a883341_12","name":"a727","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*7qwYH1r-h6VOGiE6C2tpGg.png"},"text":"Difference between unstructured (left) and structured (right) pruning: structured pruning removes both convolution filters and rows of kernels instead of just pruning connections. This leads to fewer feature maps within intermediate representations. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_13":{"__typename":"Paragraph","id":"58956a883341_13","name":"01ae","type":"H4","href":null,"layout":null,"metadata":null,"text":"1.2 — Structured pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_14":{"__typename":"Paragraph","id":"58956a883341_14","name":"d73b","type":"P","href":null,"layout":null,"metadata":null,"text":"This is the reason why many works have focused on pruning larger structures, such as whole neurons [36] or, for its direct equivalent within the more modern deep convolutional networks, convolution filters [40, 41, 66]. Filter pruning allows for an exploitable and yet fine enough granularity, as large networks tend to include numerous convolution layers, each counting up to hundreds or thousands of filters. Not only does removing such structures result in sparse layers that can be directly instantiated as thinner ones, but doing so also eliminates the feature maps that are the outputs of such filters.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_15":{"__typename":"Paragraph","id":"58956a883341_15","name":"4a73","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, not only are such networks lighter to store, due to fewer parameters, but also they require less computations and generate lighter intermediate representations, hence needing less memory during runtime. Actually, it is sometimes more beneficial to reduce bandwidth rather than the parameter count. Indeed, for tasks that involve large images, such as semantic segmentation or object detection, intermediate representations may be prohibitively memory-consuming, way more than the network itself. For these reasons, filter pruning is now seen as the default kind of structured pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":576,"end":594,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_16":{"__typename":"Paragraph","id":"58956a883341_16","name":"b13b","type":"P","href":null,"layout":null,"metadata":null,"text":"Yet, when applying such a pruning, one should pay attention to the following aspects. Let’s consider how a convolution layer is built: for Cin input channels and Cout output ones, a convolution layer is made of Cout filters, each counting Cin kernels; each filter outputs one feature map and within each filter, one kernel is dedicated to each input channel. Considering this architecture, and acknowledging a regular convolutional network basically stacks convolution layers, when pruning whole filters, one may observe that pruning a filter, and then the feature map it outputs, actually results in pruning the corresponding kernels in the ensuing layer too. That means that, when pruning filters, one may actually prune twice the amount of parameters thought to be removed in the first place.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":139,"end":142,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":162,"end":166,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":211,"end":215,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":239,"end":242,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_17":{"__typename":"Paragraph","id":"58956a883341_17","name":"920a","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s consider too that, when a whole layer happens to get pruned (which tends to happen because of layer collapse [62], but does not always break the network, depending on the architecture), the previous layer’s outputs are now totally unconnected, hence pruned too: pruning a whole layer may actually prune all its previous layers whose outputs are not somehow connected elsewhere (because of residual connections [28] or whole parallel paths [61]). Therefore, when pruning filters, one should consider computing the exact number of actually pruned parameters. Indeed, pruning the same amount of filters, depending on their distribution within the architecture, may not lead to the same actual amount of pruned parameters, making any result impossible to compare with.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":463,"end":561,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_18":{"__typename":"Paragraph","id":"58956a883341_18","name":"64ad","type":"P","href":null,"layout":null,"metadata":null,"text":"Before changing topic, let’s just mention that, albeit a minority, some works focus on pruning convolution kernels, intra-kernel structures [2,24, 46] or even specific parameter-wise structures. However, such structures need special implementations to lead to any kind of speedup (as for unstructured pruning). Another kind of exploitable structure, though, is to turn convolutions into “shift layers” by pruning all but one parameter in each kernel, which can then be summed up as a combination of a shifting operation and a 1 × 1 convolution [24].","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":159,"end":193,"href":"https:\u002F\u002Fdeveloper.nvidia.com\u002Fblog\u002Faccelerating-inference-with-sparsity-using-ampere-and-tensorrt\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png":{"__typename":"ImageMetadata","id":"1*o0Qh-ORMytWTA2xdCFbPiQ.png","originalHeight":1950,"originalWidth":2268,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_19":{"__typename":"Paragraph","id":"58956a883341_19","name":"5242","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*o0Qh-ORMytWTA2xdCFbPiQ.png"},"text":"The danger of structured pruning: altering the input and output dimensions of layers can lead to some discrepancies. If on the left, both layers output the same number of feature maps, that can be summed up well afterward, their pruned counterparts on the right produce intermediate representations of different dimensions, that cannot be summed up without processing them. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_20":{"__typename":"Paragraph","id":"58956a883341_20","name":"7400","type":"H3","href":null,"layout":null,"metadata":null,"text":"2 — Pruning criteria","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_21":{"__typename":"Paragraph","id":"58956a883341_21","name":"af47","type":"P","href":null,"layout":null,"metadata":null,"text":"Once one has decided what kind of structure to prune, the next question one may ask could be: “Now, how do I figure out which ones to keep and which ones to prune?”. To answer that one needs a proper pruning criteria, that will rank the relative importance of the parameters, filters or else.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_22":{"__typename":"Paragraph","id":"58956a883341_22","name":"a3f6","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.1 — Weight magnitude criterion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_23":{"__typename":"Paragraph","id":"58956a883341_23","name":"ab7c","type":"P","href":null,"layout":null,"metadata":null,"text":"One criterion that is quite intuitive and surprisingly efficient is pruning weights whose absolute value (or “magnitude”) is the smallest. Indeed, under the constraint of a weight-decay, those which do not contribute significantly to the function are expected to have their magnitude shrink during training. Therefore, the superfluous weights are expected to be those of lesser magnitude [8]. Notwithstanding its simplicity, the magnitude criterion is still widely used in modern works [21, 26, 58], making it a staple of the domain.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_24":{"__typename":"Paragraph","id":"58956a883341_24","name":"b739","type":"P","href":null,"layout":null,"metadata":null,"text":"However, although this criterion seems trivial to implement in the case of unstructured pruning, one may wonder how to adapt it to structured pruning. One straightforward way is to order filters depending on their norm (L 1 or L 2 for example) [40, 70]. If this method is quite straightforward one may desire to encapsulate multiple sets of parameters within one measure: for example, a convolutional filter, its bias and its batch-normalization parameters together, or even corresponding filters within parallel layers whose outputs are then fused and whose channels we would like to reduce.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_25":{"__typename":"Paragraph","id":"58956a883341_25","name":"44f2","type":"P","href":null,"layout":null,"metadata":null,"text":"One way to do that, without having to compute the combined norm of these parameters, involves inserting a learnable multiplicative parameter for each feature map after each set of layers you want to prune. This gate, when reduced to zero, effectively prunes the whole set of parameters responsible for this channel and the magnitude of this gate accounts for the importance of all of them. The method hence consists in pruning the gates of lesser magnitude [36, 41].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_26":{"__typename":"Paragraph","id":"58956a883341_26","name":"a4d6","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.2 — Gradient magnitude pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_27":{"__typename":"Paragraph","id":"58956a883341_27","name":"e034","type":"P","href":null,"layout":null,"metadata":null,"text":"Magnitude of the weight is not the only popular criterion (or family of criteria) that exists. Actually, the other main criterion to have lasted up to now is the magnitude of the gradient. Indeed, back in the 80's some fundamental works [37, 53] theorized, through a Taylor decomposition of the impact of removing a parameter on the loss, that some metrics, derived from the back-propagated gradient, may provide a good way to determine which parameters could be pruned without damaging the network.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_28":{"__typename":"Paragraph","id":"58956a883341_28","name":"50c3","type":"P","href":null,"layout":null,"metadata":null,"text":"More modern implementations of this criterion [4, 50] actually accumulate gradients over a minibatch of training data and prune on the basis of the product between this gradient and the corresponding weight of each parameter. This criterion can be applied to the aforementioned gates too [49].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_29":{"__typename":"Paragraph","id":"58956a883341_29","name":"f74e","type":"H4","href":null,"layout":null,"metadata":null,"text":"2.3 — Global or local pruning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_30":{"__typename":"Paragraph","id":"58956a883341_30","name":"7f2b","type":"P","href":null,"layout":null,"metadata":null,"text":"One final aspect to take into consideration is whether the chosen criterion is applied globally to all parameters or filters of the network, or if it is computed independently for each layer. While global pruning has proven many times to yield better results, it can lead to layer collapse [62]. A simple way to avoid this problem is to resort to layer-wise local pruning, namely pruning the same rate at each layer, when the used method cannot prevent layer collapse.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png":{"__typename":"ImageMetadata","id":"1*rMLCgVa380ZBcgM0Iqg84Q.png","originalHeight":879,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_31":{"__typename":"Paragraph","id":"58956a883341_31","name":"89e2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*rMLCgVa380ZBcgM0Iqg84Q.png"},"text":"Difference between local pruning (left) and global pruning (right): local pruning applies the same rate to each layer while global applies it on the whole network at once. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_32":{"__typename":"Paragraph","id":"58956a883341_32","name":"703c","type":"H3","href":null,"layout":null,"metadata":null,"text":"3 — Pruning method","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_33":{"__typename":"Paragraph","id":"58956a883341_33","name":"e967","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have got our pruning structure and criterion, the only parameter left is which method should we use to prune a network. This is actually the topic on which the literature can be the most confusing, as each paper will bring its own quirks and gimmicks, so much that one may get lost between what is methodically relevant and what is just a specificity of a given paper.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_34":{"__typename":"Paragraph","id":"58956a883341_34","name":"7b8d","type":"P","href":null,"layout":null,"metadata":null,"text":"This is why we will thematically overview some of the most popular families of method to prune neural networks, in an order that highlights the evolution of the use of sparsity during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_35":{"__typename":"Paragraph","id":"58956a883341_35","name":"45d5","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.1 — The classic framework: train, prune and fine-tune","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_36":{"__typename":"Paragraph","id":"58956a883341_36","name":"f197","type":"P","href":null,"layout":null,"metadata":null,"text":"The first basic framework to know is the train, prune and fine-tune method, which obviously involves 1) training the network 2) pruning it by setting to 0 all parameters targeted by the pruning structures and criterion (these parameters cannot recover afterwhile) and 3) training the network for a few extra epochs, with the lowest learning rate, to give it a chance to recover from the loss in performance induced by pruning. Usually, these last two steps can be iterated, with each time a growing pruning rate.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_37":{"__typename":"Paragraph","id":"58956a883341_37","name":"50e4","type":"P","href":null,"layout":null,"metadata":null,"text":"The method proposed by Han et al. [26] applies this method, with 5 iterations between pruning and fine-tuning, to weight magnitude pruning. Iterating has shown to improve performance, at the cost of extra computation and training time. This simple framework serves as a basis for many works [26, 40, 41, 50, 66] and can be seen as the default method over which all the others have built.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_38":{"__typename":"Paragraph","id":"58956a883341_38","name":"62f4","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.2 — Extending the classic framework","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_39":{"__typename":"Paragraph","id":"58956a883341_39","name":"3d86","type":"P","href":null,"layout":null,"metadata":null,"text":"While not straying too far, some methods have brought significant modifications to the aforementioned classic framework by Han et al. [26]. Gale et al. [21] have pushed the principle of iterations further by removing an increasing amount of weights progressively all along the training process, which allows benefiting from the advantages of iterations and to remove the whole fine-tuning process. He et al. [29] reduce prunable filters to 0, at each epoch, while not preventing them from learning and being updated afterward, in order to let their weights grow back after pruning while enforcing sparsity during training.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_40":{"__typename":"Paragraph","id":"58956a883341_40","name":"67de","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, the method of Renda et al. [58] involves fully retraining a network once it is pruned. Unlike fine-tuning, which is performed at the lowest learning-rate, retraining follows the same learning-rate schedule as training, hence its name: “Learning-Rate Rewinding”. This retraining has shown to yield better performance than mere fine-tuning, at a significantly higher cost.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_41":{"__typename":"Paragraph","id":"58956a883341_41","name":"062d","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.3 — Pruning at initialization","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_42":{"__typename":"Paragraph","id":"58956a883341_42","name":"6ba9","type":"P","href":null,"layout":null,"metadata":null,"text":"In order to speed up training, avoid fine-tuning and prevent any alteration of the architecture during or after training, multiple works have focused on pruning before training. In the wake of SNIP [39], many works have studied the use of the work of Le Cun et al. [37] or of Mozer and Smolensky [53] to prune at initialization [12, 64], including intensive theoretical studies [27, 38, 62]. However, Optimal Brain Damage [37] relies on multiple approximations including an “extremal” approximation that “assumes that parameter deletion will be performed after training has converged” [37]; this fact is rarely mentioned, even among works that are based on it. Some works have raised reservations about the ability of such methods to generate masks whose relevance outshines random ones of similar distribution per layer [20].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_43":{"__typename":"Paragraph","id":"58956a883341_43","name":"98e1","type":"P","href":null,"layout":null,"metadata":null,"text":"Another family of methods that study the relationship between pruning and initialization gravitates around the “Lottery Ticket Hypothesis” [18]. This hypothesis states that “randomly-initialized, dense neural network contains a subnet-work that is initialized such that — when trained in isolation — it can match the test accuracy of the original network after training for at most the same number of iterations”. In practice, this literature studies how well a pruning mask, defined using an already converged network, can be applied to the network back when it was just initialized. Multiple works have expanded, stabilized or studied this hypothesis [14, 19, 45, 51, 69]. However, once again multiple works tend to question the validity of the hypothesis and of the method used to study it [21, 42] and some even tend to show that its benefits rather came from the principle of fully training with the definitive mask instead of a hypothetical “Winning Ticket” [58].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png":{"__typename":"ImageMetadata","id":"1*ALVyE5U7jC692UGVKCVY8Q.png","originalHeight":838,"originalWidth":2058,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_44":{"__typename":"Paragraph","id":"58956a883341_44","name":"9383","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*ALVyE5U7jC692UGVKCVY8Q.png"},"text":"Comparison between the classic “train, prune and fine-tune” framework [26], the lottery ticket experiment [18] and learning rate rewinding [58]. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_45":{"__typename":"Paragraph","id":"58956a883341_45","name":"0d30","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.4 — Sparse training","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_46":{"__typename":"Paragraph","id":"58956a883341_46","name":"fd21","type":"P","href":null,"layout":null,"metadata":null,"text":"The previous methods are linked by a seemingly shared underlying theme: training under sparsity constraints. This principle is at the core of a family of methods, called sparse training, which consists in enforcing a constant rate of sparsity during training while its distribution varies and is progressively adjusted. Introduced by Mocanu et al. [47], it involves: 1) initializing the network with a random mask that prunes a certain proportion of the network 2) training this pruned network during one epoch 3) pruning a certain amount of weights of lower magnitude and 4) regrowing the same amount of random weights.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":170,"end":185,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_47":{"__typename":"Paragraph","id":"58956a883341_47","name":"4cad","type":"P","href":null,"layout":null,"metadata":null,"text":"That way, the pruning mask, at first random, is progressively adjusted to target the least import weights while enforcing sparsity all throughout training. The sparsity level can be the same for each layer [47] or global [52]. Other methods have extended sparse training by using a certain criterion to regrow weights instead of choosing them randomly [15, 17].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png":{"__typename":"ImageMetadata","id":"1*3hP9xPMOSnsxqtLIvGrhOA.png","originalHeight":1217,"originalWidth":2048,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:58956a883341_48":{"__typename":"Paragraph","id":"58956a883341_48","name":"ecaa","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*3hP9xPMOSnsxqtLIvGrhOA.png"},"text":"Sparse training cuts and grows different weights periodically during training, which leads to an adjusted mask that should target only relevant parameters. (image by author)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_49":{"__typename":"Paragraph","id":"58956a883341_49","name":"f9f3","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.5 — Mask learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_50":{"__typename":"Paragraph","id":"58956a883341_50","name":"88ec","type":"P","href":null,"layout":null,"metadata":null,"text":"Instead of relying on arbitrary criteria to prune or regrow weights, multiple methods focus on learning a pruning mask during training. Two types of methods seem to prevail in this domain: 1) mask learning through separate networks or layers and 2) mask learning through auxiliary parameters. Multiple kinds of strategies can fit in the methods of the first type: training separate agents to prune as many filters of a layer as possible while maximizing the accuracy [33], inserting attention-based layers [68] or using reinforcement learning [30]. The second kind of methods aims at considering pruning as an optimization problem that tends to minimize both the L0 norm of the network and its supervised loss.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_51":{"__typename":"Paragraph","id":"58956a883341_51","name":"1475","type":"P","href":null,"layout":null,"metadata":null,"text":"Since the L0 is non-differentiable, the various methods mainly involve circumventing this problem through the use of penalized auxiliary parameters that are multiplied with their corresponding parameter during the forward pass [59, 23]. Many methods [44, 60, 67] rely on a method analogous to that of “Binary Connect” [11], namely: applying stochastic gates over parameters whose values are each randomly drawn from their own Bernoulli distribution of parameter p that is learned using a “Straight Through Estimator” [3] or other means [44].","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":462,"end":463,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_52":{"__typename":"Paragraph","id":"58956a883341_52","name":"7a36","type":"H4","href":null,"layout":null,"metadata":null,"text":"3.6 — Penalty-based methods","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_53":{"__typename":"Paragraph","id":"58956a883341_53","name":"b905","type":"P","href":null,"layout":null,"metadata":null,"text":"Many methods, instead of pruning connections manually or penalizing auxiliary parameters, rather apply various kinds of penalties to weights themselves to make them progressively shrink toward 0. This notion is actually pretty ancient [57], as weight-decay is already an essential element to the weight magnitude criterion. Beyond using a mere weight-decay, even back then multiple works focused on elaborating penalties specifically designed to enforce sparsity [55, 65]. Today, various methods apply different regularizations, on top of the weight decay, to increase further the sparsity (typically, using L 1 norm [41]).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_54":{"__typename":"Paragraph","id":"58956a883341_54","name":"ba3b","type":"P","href":null,"layout":null,"metadata":null,"text":"Among modern works, multiple methods rely on the LASSO (Least Absolute Shrinkage and Selection Operator) [22, 31, 66] to prune weights or groups. Other methods develop penalties that target weak connections to increase the gap between the parameters to keep and those to prune, so that their removal has less impact [7, 16]. Some methods show that targeting a subset of weights with a penalization that grows all throughout training can progressively prune them and make their removal seamless [6, 9, 63]. The literature also counts a whole range of methods built around the principle of “Variational Dropout” [34], a method based on variational inference [5] applied to deep learning [35]. As a pruning method [48], it birthed multiple works that adapt its principle to structured pruning [43, 54].","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_55":{"__typename":"Paragraph","id":"58956a883341_55","name":"344e","type":"H3","href":null,"layout":null,"metadata":null,"text":"4 — Available frameworks","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_56":{"__typename":"Paragraph","id":"58956a883341_56","name":"d420","type":"P","href":null,"layout":null,"metadata":null,"text":"If most of these methods have to be implemented from scratch (or can be reused from the provided sources of each paper, if they do provide them), some frameworks exist to apply basic methods or make the aforementioned implementation easier.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_57":{"__typename":"Paragraph","id":"58956a883341_57","name":"1145","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.1 — Pytorch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_58":{"__typename":"Paragraph","id":"58956a883341_58","name":"9c63","type":"P","href":null,"layout":null,"metadata":null,"text":"Pytorch [56] provide multiple quality-of-life features to help pruning networks. The provided tools allow to easily apply a mask to a network and maintain this mask during training, as well as it allows to easily revert that mask if needed. Pytorch also provide some basic pruning methods, such as global or local pruning, whether it is structured or not. Structured pruning can be applied on any dimension of the weights tensors, which lets pruning filters, rows of kernels or even some rows and columns inside kernels. Those in-built basic methods also allow pruning randomly or depending on various norms.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_59":{"__typename":"Paragraph","id":"58956a883341_59","name":"3f1c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.2 — Tensorflow","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_60":{"__typename":"Paragraph","id":"58956a883341_60","name":"db73","type":"P","href":null,"layout":null,"metadata":null,"text":"The Keras [10] library from Tensorflow [1] provide some basic tools to prune weights of lower magnitudes. Such as in the work of Han et al [25], the efficiency of pruning is measured in terms of how much does the redundancy, introduced by all the inserted zeros, allows to compress the model better (which combines well with quantization).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":4,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":28,"end":38,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_61":{"__typename":"Paragraph","id":"58956a883341_61","name":"c61c","type":"H4","href":null,"layout":null,"metadata":null,"text":"4.3 — ShrinkBench","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_62":{"__typename":"Paragraph","id":"58956a883341_62","name":"29c2","type":"P","href":null,"layout":null,"metadata":null,"text":"Blalock et al. [4] provide in their work a custom library in an effort to help the community normalize how pruning algorithm are compared. Based on Pytorch, ShrinkBench aims at making the implementation of pruning methods easier while normalizing the conditions under which they are trained and tested. It provides different baselines, such as random pruning, global or layerwise and weight magnitude or gradient magnitude pruning.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":148,"end":155,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":157,"end":168,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_63":{"__typename":"Paragraph","id":"58956a883341_63","name":"0db7","type":"H3","href":null,"layout":null,"metadata":null,"text":"5 — Brief recap of reviewed methods","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_64":{"__typename":"Paragraph","id":"58956a883341_64","name":"4f0a","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, many papers have been cited. Here is a simple table to roughly summarize what they do and what differentiates them (provided dates are those of first publication):","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c":{"__typename":"MediaResource","id":"5b60387af4bb2dc372bdb5cd4701b98c","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"Neural Network Pruning Methods"},"Paragraph:58956a883341_65":{"__typename":"Paragraph","id":"58956a883341_65","name":"0635","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:5b60387af4bb2dc372bdb5cd4701b98c"}},"mixtapeMetadata":null},"Paragraph:58956a883341_66":{"__typename":"Paragraph","id":"58956a883341_66","name":"5fc5","type":"H3","href":null,"layout":null,"metadata":null,"text":"6 — Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_67":{"__typename":"Paragraph","id":"58956a883341_67","name":"dbd7","type":"P","href":null,"layout":null,"metadata":null,"text":"In our quick overview of the literature, we saw that 1) pruning structures define which kind of gain to expect from pruning 2) pruning criteria are based on various theoretical or practical justifications and 3) pruning methods tend to revolve around introducing sparsity during training to reconcile performance and cost. We also saw that, even though its founding works date back from the late 80’s, neural network pruning is a very dynamic field that still experiences fundamental discoveries and new basic concepts today.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_68":{"__typename":"Paragraph","id":"58956a883341_68","name":"8cda","type":"P","href":null,"layout":null,"metadata":null,"text":"Despite the daily contributions in the domain, there seems to be still plenty of room for exploration and innovation. If each subfamily of method can be seen as an attempt to answer a question (“How to regrow pruned weights ?”, “How to learn pruning masks through optimization ?”, “How to relax the weight removal by a softer mean ?”…), then the evolution of the literature seems to point out a certain direction: that of sparsity throughout training. This direction raises itself many questions, such as: “do pruning criteria work well on networks that haven’t converged yet?” or “how to tell the benefit of the choice of the weights to prune from that of training with any kind of sparsity from the start?”","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_69":{"__typename":"Paragraph","id":"58956a883341_69","name":"b0a7","type":"H3","href":null,"layout":null,"metadata":null,"text":"References","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_70":{"__typename":"Paragraph","id":"58956a883341_70","name":"333c","type":"P","href":null,"layout":null,"metadata":null,"text":"[1] Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from tensorflow.org.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_71":{"__typename":"Paragraph","id":"58956a883341_71","name":"1fba","type":"P","href":null,"layout":null,"metadata":null,"text":"[2] Sajid Anwar, Kyuyeon Hwang, and Wonyong Sung. Structured pruning of deep convolutional neural networks. ACM Journal on Emerging Technologies in Computing Systems (JETC), 13(3):1–18, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_72":{"__typename":"Paragraph","id":"58956a883341_72","name":"9ab6","type":"P","href":null,"layout":null,"metadata":null,"text":"[3] Yoshua Bengio, Nicholas Léonard, and Aaron Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_73":{"__typename":"Paragraph","id":"58956a883341_73","name":"4225","type":"P","href":null,"layout":null,"metadata":null,"text":"[4] Davis Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John Guttag. What is the state of neural network pruning? arXiv preprint arXiv:2003.03033, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_74":{"__typename":"Paragraph","id":"58956a883341_74","name":"1893","type":"P","href":null,"layout":null,"metadata":null,"text":"[5] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians. Journal of the American statistical Association, 112(518):859–877, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_75":{"__typename":"Paragraph","id":"58956a883341_75","name":"4edf","type":"P","href":null,"layout":null,"metadata":null,"text":"[6] Miguel A Carreira-Perpinán and Yerlan Idelbayev. “learning-compression” algorithms for neural net pruning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8532–8541, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_76":{"__typename":"Paragraph","id":"58956a883341_76","name":"5a92","type":"P","href":null,"layout":null,"metadata":null,"text":"[7] Jing Chang and Jin Sha. Prune deep neural networks with the modified L1\u002F2 penalty. IEEE Access, 7:2273–2280, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_77":{"__typename":"Paragraph","id":"58956a883341_77","name":"7d74","type":"P","href":null,"layout":null,"metadata":null,"text":"[8] Yves Chauvin. A back-propagation algorithm with optimal use of hidden units. In NIPS, volume 1, pages 519–526, 1988.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_78":{"__typename":"Paragraph","id":"58956a883341_78","name":"2b0e","type":"P","href":null,"layout":null,"metadata":null,"text":"[9] Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee. Compression of deep convolutional neural networks under joint sparsity constraints. arXiv preprint arXiv:1805.08303, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_79":{"__typename":"Paragraph","id":"58956a883341_79","name":"5860","type":"P","href":null,"layout":null,"metadata":null,"text":"[10] Francois Chollet et al. Keras, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_80":{"__typename":"Paragraph","id":"58956a883341_80","name":"a78f","type":"P","href":null,"layout":null,"metadata":null,"text":"[11] Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David. Binaryconnect: Training deep neural networks with binary weights during propagations. In NIPS, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_81":{"__typename":"Paragraph","id":"58956a883341_81","name":"f314","type":"P","href":null,"layout":null,"metadata":null,"text":"[12] Pau de Jorge, Amartya Sanyal, Harkirat S Behl, Philip HS Torr, Gregory Rogez, and Puneet K Dokania. Progressive skeletonization: Trimming more fat from a network at initialization. arXiv preprint arXiv:2006.09081, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_82":{"__typename":"Paragraph","id":"58956a883341_82","name":"5849","type":"P","href":null,"layout":null,"metadata":null,"text":"[13] Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus. Exploiting linear structure within convolutional networks for efficient evaluation. In 28th Annual Conference on Neural Information Processing Systems 2014, NIPS 2014, pages 1269–1277. Neural information processing systems foundation, 2014.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_83":{"__typename":"Paragraph","id":"58956a883341_83","name":"2aed","type":"P","href":null,"layout":null,"metadata":null,"text":"[14] Shrey Desai, Hongyuan Zhan, and Ahmed Aly. Evaluating lottery tickets under distributional shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_84":{"__typename":"Paragraph","id":"58956a883341_84","name":"eb74","type":"P","href":null,"layout":null,"metadata":null,"text":"[15] Tim Dettmers and Luke Zettlemoyer. Sparse networks from scratch: Faster training without losing performance. arXiv preprint arXiv:1907.04840, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_85":{"__typename":"Paragraph","id":"58956a883341_85","name":"b415","type":"P","href":null,"layout":null,"metadata":null,"text":"[16] Xiaohan Ding, Guiguang Ding, Xiangxin Zhou, Yuchen Guo, Jungong Han, and Ji Liu. Global sparse momentum sgd for pruning very deep neural networks. arXiv preprint arXiv:1909.12778, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_86":{"__typename":"Paragraph","id":"58956a883341_86","name":"f184","type":"P","href":null,"layout":null,"metadata":null,"text":"[17] Utku Evci, Trevor Gale, Jacob Menick, Pablo Samuel Castro, and Erich Elsen. Rigging the lottery: Making all tickets winners. In International Conference on Machine Learning, pages 2943–2952. PMLR, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_87":{"__typename":"Paragraph","id":"58956a883341_87","name":"bf6f","type":"P","href":null,"layout":null,"metadata":null,"text":"[18] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_88":{"__typename":"Paragraph","id":"58956a883341_88","name":"3617","type":"P","href":null,"layout":null,"metadata":null,"text":"[19] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Stabilizing the lottery ticket hypothesis. arXiv preprint arXiv:1903.01611, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_89":{"__typename":"Paragraph","id":"58956a883341_89","name":"58c0","type":"P","href":null,"layout":null,"metadata":null,"text":"[20] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. Pruning neural networks at initialization: Why are we missing the mark? arXiv preprint arXiv:2009.08576, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_90":{"__typename":"Paragraph","id":"58956a883341_90","name":"4f5f","type":"P","href":null,"layout":null,"metadata":null,"text":"[21] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. arXiv preprint arXiv:1902.09574, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_91":{"__typename":"Paragraph","id":"58956a883341_91","name":"74d8","type":"P","href":null,"layout":null,"metadata":null,"text":"[22] Susan Gao, Xin Liu, Lung-Sheng Chien, William Zhang, and Jose M Alvarez. Vacl: Variance-aware cross-layer regularization for pruning deep residual networks. In Proceedings of the IEEE\u002FCVF International Conference on Computer Vision Workshops, pages 0–0, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_92":{"__typename":"Paragraph","id":"58956a883341_92","name":"a37e","type":"P","href":null,"layout":null,"metadata":null,"text":"[23] Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In NIPS, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_93":{"__typename":"Paragraph","id":"58956a883341_93","name":"771a","type":"P","href":null,"layout":null,"metadata":null,"text":"[24] Ghouthi Boukli Hacene, Carlos Lassance, Vincent Gripon, Matthieu Courbariaux, and Yoshua Bengio. Attention based pruning for shift networks. In 2020 25th International Conference on Pattern Recognition (ICPR), pages 4054–4061. IEEE, 2021.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_94":{"__typename":"Paragraph","id":"58956a883341_94","name":"c933","type":"P","href":null,"layout":null,"metadata":null,"text":"[25] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_95":{"__typename":"Paragraph","id":"58956a883341_95","name":"a6e9","type":"P","href":null,"layout":null,"metadata":null,"text":"[26] Song Han, Jeff Pool, John Tran, and William J Dally. Learning both weights and connections for efficient neural network. In NIPS, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_96":{"__typename":"Paragraph","id":"58956a883341_96","name":"3b8d","type":"P","href":null,"layout":null,"metadata":null,"text":"[27] Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, and Yee Whye Teh. Robust pruning at initialization.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_97":{"__typename":"Paragraph","id":"58956a883341_97","name":"ff92","type":"P","href":null,"layout":null,"metadata":null,"text":"[28] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_98":{"__typename":"Paragraph","id":"58956a883341_98","name":"9f85","type":"P","href":null,"layout":null,"metadata":null,"text":"[29] Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi Yang. Soft filter pruning for accelerating deep convolutional neural networks. arXiv preprint arXiv:1808.06866, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_99":{"__typename":"Paragraph","id":"58956a883341_99","name":"14d2","type":"P","href":null,"layout":null,"metadata":null,"text":"[30] Yihui He, Ji Lin, Zhijian Liu, Hanrui Wang, Li-Jia Li, and Song Han. Amc: Automl for model compression and acceleration on mobile devices. In Proceedings of the European Conference on Computer Vision (ECCV), pages 784–800, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_100":{"__typename":"Paragraph","id":"58956a883341_100","name":"af2f","type":"P","href":null,"layout":null,"metadata":null,"text":"[31] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1389–1397, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_101":{"__typename":"Paragraph","id":"58956a883341_101","name":"7371","type":"P","href":null,"layout":null,"metadata":null,"text":"[32] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. stat, 1050:9, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_102":{"__typename":"Paragraph","id":"58956a883341_102","name":"55ce","type":"P","href":null,"layout":null,"metadata":null,"text":"[33] Qiangui Huang, Kevin Zhou, Suya You, and Ulrich Neumann. Learning to prune filters in convolutional neural networks. In 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pages 709–718. IEEE, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_103":{"__typename":"Paragraph","id":"58956a883341_103","name":"3f8f","type":"P","href":null,"layout":null,"metadata":null,"text":"[34] Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. stat, 1050:8, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_104":{"__typename":"Paragraph","id":"58956a883341_104","name":"93d7","type":"P","href":null,"layout":null,"metadata":null,"text":"[35] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. stat, 1050:1, 2014.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_105":{"__typename":"Paragraph","id":"58956a883341_105","name":"38d1","type":"P","href":null,"layout":null,"metadata":null,"text":"[36] John K Kruschke and Javier R Movellan. Benefits of gain: Speeded learning and minimal hidden layers in back-propagation networks. IEEE Transactions on systems, Man, and Cybernetics, 21(1):273–280, 1991.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_106":{"__typename":"Paragraph","id":"58956a883341_106","name":"1b89","type":"P","href":null,"layout":null,"metadata":null,"text":"[37] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural information processing systems, pages 598–605, 1990.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_107":{"__typename":"Paragraph","id":"58956a883341_107","name":"b9d6","type":"P","href":null,"layout":null,"metadata":null,"text":"[38] Namhoon Lee, Thalaiyasingam Ajanthan, Stephen Gould, and Philip HS Torr. A signal propagation perspective for pruning neural networks at initialization. In International Conference on Learning Representations, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_108":{"__typename":"Paragraph","id":"58956a883341_108","name":"c8c3","type":"P","href":null,"layout":null,"metadata":null,"text":"[39] Namhoon Lee, Thalaiyasingam Ajanthan, and Philip HS Torr. Snip: Single-shot network pruning based on connection sensitivity. International Conference on Learning Representations, ICLR, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_109":{"__typename":"Paragraph","id":"58956a883341_109","name":"fa53","type":"P","href":null,"layout":null,"metadata":null,"text":"[40] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. arXiv preprint arXiv:1608.08710, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_110":{"__typename":"Paragraph","id":"58956a883341_110","name":"5975","type":"P","href":null,"layout":null,"metadata":null,"text":"[41] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang. Learning efficient convolutional networks through network slimming. In Proceedings of the IEEE International Conference on Computer Vision, pages 2736–2744, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_111":{"__typename":"Paragraph","id":"58956a883341_111","name":"3879","type":"P","href":null,"layout":null,"metadata":null,"text":"[42] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value of network pruning. In International Conference on Learning Representations, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_112":{"__typename":"Paragraph","id":"58956a883341_112","name":"8d02","type":"P","href":null,"layout":null,"metadata":null,"text":"[43] C Louizos, K Ullrich, and M Welling. Bayesian compression for deep learning. In 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA., 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_113":{"__typename":"Paragraph","id":"58956a883341_113","name":"eb44","type":"P","href":null,"layout":null,"metadata":null,"text":"[44] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks through l 0 regularization. arXiv preprint arXiv:1712.01312, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_114":{"__typename":"Paragraph","id":"58956a883341_114","name":"4866","type":"P","href":null,"layout":null,"metadata":null,"text":"[45] Eran Malach, Gilad Yehudai, Shai Shalev-Schwartz, and Ohad Shamir. Proving the lottery ticket hypothesis: Pruning is all you need. In International Conference on Machine Learning, pages 6682–6691. PMLR, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_115":{"__typename":"Paragraph","id":"58956a883341_115","name":"235f","type":"P","href":null,"layout":null,"metadata":null,"text":"[46] Huizi Mao, Song Han, Jeff Pool, Wenshuo Li, Xingyu Liu, Yu Wang, and William J Dally. Exploring the regularity of sparse structure in convolutional neural networks. arXiv preprint arXiv:1705.08922, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_116":{"__typename":"Paragraph","id":"58956a883341_116","name":"6721","type":"P","href":null,"layout":null,"metadata":null,"text":"[47] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. Nature communications, 9(1):1–12, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_117":{"__typename":"Paragraph","id":"58956a883341_117","name":"2a85","type":"P","href":null,"layout":null,"metadata":null,"text":"[48] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsifies deep neural networks. In International Conference on Machine Learning, pages 2498–2507. PMLR, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_118":{"__typename":"Paragraph","id":"58956a883341_118","name":"9f44","type":"P","href":null,"layout":null,"metadata":null,"text":"[49] Pavlo Molchanov, Arun Mallya, Stephen Tyree, Iuri Frosio, and Jan Kautz. Importance estimation for neural network pruning. In Proceedings of the IEEE\u002FCVF Conference on Computer Vision and Pattern Recognition, pages 11264–11272, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_119":{"__typename":"Paragraph","id":"58956a883341_119","name":"1ef1","type":"P","href":null,"layout":null,"metadata":null,"text":"[50] Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz. Pruning convolutional neural networks for resource efficient inference. arXiv preprint arXiv:1611.06440, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_120":{"__typename":"Paragraph","id":"58956a883341_120","name":"aa9b","type":"P","href":null,"layout":null,"metadata":null,"text":"[51] Ari S Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. stat, 1050:6, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_121":{"__typename":"Paragraph","id":"58956a883341_121","name":"79eb","type":"P","href":null,"layout":null,"metadata":null,"text":"[52] Hesham Mostafa and Xin Wang. Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization. In International Conference on Machine Learning, pages 4646–4655. PMLR, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_122":{"__typename":"Paragraph","id":"58956a883341_122","name":"ce0a","type":"P","href":null,"layout":null,"metadata":null,"text":"[53] Michael C Mozer and Paul Smolensky. Skeletonization: A technique for trimming the fat from a network via relevance assessment. In Advances in neural information processing systems, pages 107–115, 1989.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_123":{"__typename":"Paragraph","id":"58956a883341_123","name":"d3f1","type":"P","href":null,"layout":null,"metadata":null,"text":"[54] Kirill Neklyudov, Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 6778–6787, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_124":{"__typename":"Paragraph","id":"58956a883341_124","name":"bc88","type":"P","href":null,"layout":null,"metadata":null,"text":"[55] Steven J Nowlan and Geoffrey E Hinton. Simplifying neural networks by soft weight-sharing. Neural Computation, 4(4):473–493, 1992.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_125":{"__typename":"Paragraph","id":"58956a883341_125","name":"b046","type":"P","href":null,"layout":null,"metadata":null,"text":"[56] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_126":{"__typename":"Paragraph","id":"58956a883341_126","name":"d7b3","type":"P","href":null,"layout":null,"metadata":null,"text":"[57] Russell Reed. Pruning algorithms-a survey. IEEE transactions on Neural Networks, 4(5):740–747, 1993.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_127":{"__typename":"Paragraph","id":"58956a883341_127","name":"3bf3","type":"P","href":null,"layout":null,"metadata":null,"text":"[58] Alex Renda, Jonathan Frankle, and Michael Carbin. Comparing rewinding and fine-tuning in neural network pruning. arXiv preprint arXiv:2003.02389, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_128":{"__typename":"Paragraph","id":"58956a883341_128","name":"3d25","type":"P","href":null,"layout":null,"metadata":null,"text":"[59] Pedro Savarese, Hugo Silva, and Michael Maire. Winning the lottery with continuous sparsification. Advances in Neural Information Processing Systems, 33, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_129":{"__typename":"Paragraph","id":"58956a883341_129","name":"5eb0","type":"P","href":null,"layout":null,"metadata":null,"text":"[60] Suraj Srinivas, Akshayvarun Subramanya, and R Venkatesh Babu. Training sparse neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 138–145, 2017.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_130":{"__typename":"Paragraph","id":"58956a883341_130","name":"5fd8","type":"P","href":null,"layout":null,"metadata":null,"text":"[61] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1–9, 2015.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_131":{"__typename":"Paragraph","id":"58956a883341_131","name":"1d5f","type":"P","href":null,"layout":null,"metadata":null,"text":"[62] Hidenori Tanaka, Daniel Kunin, Daniel L Yamins, and Surya Ganguli. Pruning neural networks without any data by iteratively conserving synaptic flow. Advances in Neural Information Processing Systems, 33, 2020.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_132":{"__typename":"Paragraph","id":"58956a883341_132","name":"44d2","type":"P","href":null,"layout":null,"metadata":null,"text":"[63] Hugo Tessier, Vincent Gripon, Mathieu Léonardon, Matthieu Arzel, Thomas Hannagan, and David Bertrand. Rethinking weight decay for efficient neural network pruning. 2021.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_133":{"__typename":"Paragraph","id":"58956a883341_133","name":"1727","type":"P","href":null,"layout":null,"metadata":null,"text":"[64] Chaoqi Wang, Guodong Zhang, and Roger Grosse. Picking winning tickets before training by preserving gradient flow. In International Conference on Learning Representations, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_134":{"__typename":"Paragraph","id":"58956a883341_134","name":"c94b","type":"P","href":null,"layout":null,"metadata":null,"text":"[65] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-elimination with application to forecasting. In Advances in neural information processing systems, pages 875–882, 1991.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_135":{"__typename":"Paragraph","id":"58956a883341_135","name":"ce36","type":"P","href":null,"layout":null,"metadata":null,"text":"[66] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in deep neural networks. In NIPS, 2016.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_136":{"__typename":"Paragraph","id":"58956a883341_136","name":"45b5","type":"P","href":null,"layout":null,"metadata":null,"text":"[67] Xia Xiao, Zigeng Wang, and Sanguthevar Rajasekaran. Autoprune: Automatic network pruning by regularizing auxiliary parameters. Advances in neural information processing systems, 32, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_137":{"__typename":"Paragraph","id":"58956a883341_137","name":"8e2b","type":"P","href":null,"layout":null,"metadata":null,"text":"[68] Kohei Yamamoto and Kurato Maeno. Pcas: Pruning channels with attention statistics for deep network compression. arXiv preprint arXiv:1806.05382, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_138":{"__typename":"Paragraph","id":"58956a883341_138","name":"7479","type":"P","href":null,"layout":null,"metadata":null,"text":"[69] Hattie Zhou, Janice Lan, Rosanne Liu, and Jason Yosinski. Deconstructing lottery tickets: Zeros, signs, and the supermask. arXiv preprint arXiv:1905.01067, 2019.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:58956a883341_139":{"__typename":"Paragraph","id":"58956a883341_139","name":"726f","type":"P","href":null,"layout":null,"metadata":null,"text":"[70] Zhuangwei Zhuang, Mingkui Tan, Bohan Zhuang, Jing Liu, Yong Guo, Qingyao Wu, Junzhou Huang, and Jin-Hui Zhu. Discrimination-aware channel pruning for deep neural networks. In NeurIPS, 2018.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_a4e000747f83":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_a4e000747f83","isEditor":false},"Tag:neural-networks":{"__typename":"Tag","id":"neural-networks","displayTitle":"Neural Networks","normalizedTagSlug":"neural-networks"},"Tag:pruning":{"__typename":"Tag","id":"pruning","displayTitle":"Pruning","normalizedTagSlug":"pruning"},"Tag:compression":{"__typename":"Tag","id":"compression","displayTitle":"Compression","normalizedTagSlug":"compression"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"User:7e12c71dfa81":{"__typename":"User","atsQualifiedAt":1612205680542,"id":"7e12c71dfa81"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.a5b80d19.js"></script><script src="https://cdn-client.medium.com/lite/static/js/8493.58a29e31.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.359a5523.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.c71f0248.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.bbdcaa9d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9658.17030d28.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/799.361fd2fb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1860.abea291f.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3838.7ae103cd.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2905.21128cd9.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8007.e7e42be3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8695.ac0f83b3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8.5980bcd4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9683.6f872dd8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7702.c5a5a368.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5203.23a22ad8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8708.546db97b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1957.6c5d9d7a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9174.13cf10e7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3635.c351368e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5472.a7dd22a2.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4129.9a8d63eb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8580.e792aa8d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1802.0f7ac4a6.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2371.6ba1ff25.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4078.182beff5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8093.f160e4e4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1743.42985c62.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3115.4bc827fe.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2287.a89f9d21.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7089.d69c832a.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2092.0b9868e3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8824.e4a9134e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9225.9cfbe85d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6804.9f6509a8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8051.3f4b510b.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1069.ec72bd6d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5076.1a6c0ef7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/847.383abb1d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8316.a8c19480.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8793.496b82a7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8908.ed51a30d.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.1bb15d52.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5627.c45a7fb4.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8880.97b5ed81.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.RightColumnContent.153512e3.chunk.js"></script><script>window.main();</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js/v52afc6f149f6479b8c77fa569edb01181681764108816" integrity="sha512-jGCTpDpBAYDGNYR5ztKt4BQPGef1P0giN6ZGVUi835kFF88FOmmn8jBQWNgrNd8g/Yu421NdgWhwQoaOPFflDw==" data-cf-beacon='{"rayId":"7bb92af06cdf35b8","version":"2023.3.0","b":1,"token":"0b5f665943484354a59c39c6833f7078","si":100}' crossorigin="anonymous"></script>
</body></html>